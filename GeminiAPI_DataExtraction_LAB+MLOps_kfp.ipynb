{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "copyright"
      },
      "outputs": [],
      "source": [
        "# Created on April 2024 by Go Reply (based on Google's resources)\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title:generic"
      },
      "source": [
        "# Vertex AI Pipeline for Tabular Data Extraction\n",
        "*MLOps Pipeline control structures using [the Kubeflow Pipelines (KFP) SDK](https://www.kubeflow.org/docs/components/pipelines/v2/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "objective:pipelines,control"
      },
      "source": [
        "### Objective\n",
        "\n",
        "This pipeline evaluates accuracy of Gen AI for tabular data extraction.\n",
        "It uses the following Google Cloud ML services:\n",
        "- Gemini API\n",
        "- Document AI\n",
        "- Vertex AI Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "costs"
      },
      "source": [
        "### Costs\n",
        "\n",
        "Billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Estimated costs to be calculated using: the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "\n",
        "*For more details on [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_aip:mbsdk"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the packages required for executing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y73XhHDQWRO-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718839376759,
          "user_tz": -60,
          "elapsed": 15126,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58e9f9f-228e-40d6-f02b-c057fefce52a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform  \\\n",
        "                                 google-cloud-storage \\\n",
        "                                 kfp \\\n",
        "                                 PyMuPDF \\\n",
        "                                 google-cloud-pipeline-components \\\n",
        "                                 tensorflow-metadata \\\n",
        "                                 pypdf2 \\\n",
        "                                 json5 \\\n",
        "                                 google-cloud-documentai==2.22.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718663315936,
          "user_tz": -60,
          "elapsed": 79,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d4b9c424-17a5-46ba-a0b4-5433eb3fa1b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager).\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oM1iC_MfAts1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840088669,
          "user_tz": -60,
          "elapsed": 1173,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2d843488-4ccd-4316-8950-878212566aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"gen-ai-sandbox\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iACvle0jWRO_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840090530,
          "user_tz": -60,
          "elapsed": 60,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "REGION = \"europe-west2\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below.\n",
        "\n",
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated.\n",
        "\n",
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "#from google.colab import auth\n",
        "#auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6b2ccc891ed"
      },
      "source": [
        "**4. Service account or other**\n",
        "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = \"gs://ratecards-eval-gen-ai-sandbox-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "set_service_account"
      },
      "source": [
        "#### Service Account\n",
        "\n",
        "**If you don't know your service account**, try to get your service account using `gcloud` command by executing the second cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L84uFp2KWRPA"
      },
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT = \"230294883006-compute@developer.gserviceaccount.com\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autoset_service_account"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if (\n",
        "    SERVICE_ACCOUNT == \"\"\n",
        "    or SERVICE_ACCOUNT is None\n",
        "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
        "):\n",
        "    # Get your service account from gcloud\n",
        "    if not IS_COLAB:\n",
        "        shell_output = !gcloud auth list 2>/dev/null\n",
        "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
        "\n",
        "    if IS_COLAB:\n",
        "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
        "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "    print(\"Service Account:\", SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "set_service_account:pipelines"
      },
      "source": [
        "#### Set service account access for Vertex AI Pipelines\n",
        "\n",
        "Run the following commands to grant your service account access to read and write pipeline artifacts in the bucket that you created in the previous step -- you only need to run these once per service account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGS5TJtPWRPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718700451445,
          "user_tz": -60,
          "elapsed": 6482,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c701e8fd-a439-476c-c071-599325518ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes made to gs://ratecards-eval-gen-ai-sandbox-unique/\n",
            "No changes made to gs://ratecards-eval-gen-ai-sandbox-unique/\n"
          ]
        }
      ],
      "source": [
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
        "\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_vars"
      },
      "source": [
        "### Set up variables\n",
        "\n",
        "Next, set up some variables used throughout the tutorial.\n",
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "import_aip:mbsdk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718839669584,
          "user_tz": -60,
          "elapsed": 64,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import json5\n",
        "import fitz\n",
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason, Image\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "from google.cloud import storage\n",
        "from google.cloud import bigquery\n",
        "from PyPDF2 import PdfReader, PdfWriter\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import io\n",
        "import pandas as pd\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import documentai as docai\n",
        "from typing import Optional, Sequence, MutableSequence, Tuple\n",
        "#from google.cloud import documentai_v1beta3 as docai\n",
        "\n",
        "import google.cloud.aiplatform as aip\n",
        "from kfp import compiler, dsl\n",
        "from kfp.dsl import component, Metrics, Output, Artifact, ClassificationMetrics, Input\n",
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "# Initial Setup\n",
        "#################\n",
        "DATASET_ID = \"ratecard_extraction\"\n",
        "destination_table = \"extracted_ratecards\"\n",
        "#__________________\n",
        "mime_type =\"application/pdf\"\n",
        "processor_display_name = \"rate_card_extractor\"\n",
        "processor_id =\"69046f38bcccfa47\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vertex AI Initialisation\n",
        "\n",
        "Setup up the Gen AI model from Vertex AI:"
      ],
      "metadata": {
        "id": "ZyNaEhw0Ve3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
        "\n",
        "model = GenerativeModel(\"gemini-1.5-pro-001\") # Only in us-central1 - (\"gemini-experimental\")\n",
        "extraction_model = GenerativeModel(\"gemini-1.5-pro-001\")"
      ],
      "metadata": {
        "id": "tH6xqeGRVgiT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840094490,
          "user_tz": -60,
          "elapsed": 61,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create you own Data Extraction Function!"
      ],
      "metadata": {
        "id": "8g7S02LZ1x04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your own prompt to Extract Structured data from the document\n",
        "\n",
        "my_extraction_prompt = \"\"\n",
        "\n",
        "def extract_pdf_content(pdf_path,prompt, temperature=1):\n",
        " # pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        " with open(pdf_path, \"rb\") as f:\n",
        "    pdf_file = Part.from_data(data=f.read(), mime_type=\"application/pdf\")\n",
        "\n",
        " generation_config = {\n",
        "   \"max_output_tokens\": 8192,\n",
        "   \"temperature\": temperature,\n",
        "   \"top_p\": 0.95,\n",
        " }\n",
        " content = [pdf_file, prompt]\n",
        " responses= model.generate_content(content, generation_config=generation_config)\n",
        " return responses.text\n",
        "\n",
        "extract_pdf_content(\"Sample-SoW.pdf\", my_extraction_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "jvjEHgwf12ya",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840318931,
          "user_tz": -60,
          "elapsed": 6448,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e839d29c-ff2c-4186-a955-652fd3af4dc3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The document is a Work Order for IT Professional services between Pluto Telecom and Alphatech (UK) Limited. \\n\\n**Key details of the Work Order:**\\n\\n* **Project Name:** Project 20 - Requirement to Update Discount IDs\\n* **Project Description:** Pluto Telecom is launching a new portfolio of plans with unlimited data and tiered network speeds. Alphatech is tasked with creating 3 new business plans and 6 new consumer plans on the Legacy system. These new plans will replace existing equivalent plans.\\n* **Project Timeline:** The project will run from April 24th, 2020 to April 30th, 2020.\\n* **Pricing Model:** Fixed Price \\n* **Total Price:** €2,186.10\\n\\n**Other notable information:**\\n\\n* This Work Order is not legally binding until the corresponding Purchase Order is accepted.\\n* The Pluto Telecom Procurement Agreement governs this Work Order and can only be changed through a formal Variation Agreement.\\n\\nThis document outlines the scope of work, timeline, and payment terms for the project. It serves as a legally binding agreement once the corresponding Purchase Order is accepted. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Rate Cards"
      ],
      "metadata": {
        "id": "wbU3PqCn3h6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Engineering\n",
        "\n",
        "Set up the necessary prompts for the extraction of tabular information"
      ],
      "metadata": {
        "id": "B7DFquARV5Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "structure_prompt= \"\"\"Objective: Accurately identify all rate card tables within the provided PDF document that deal with financial information, and extract formatting details for full reliable table boundary detection. The output must be a strictly valid JSON format.**Avoid using double quotes within values; instead, use single quotes or escape them.**\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Table Recognition:\n",
        "*   Only look specifially for rate card tables, where the table deals with financial or pricing information\n",
        "*   Do not return information for tables that are not explicitly rate cards\n",
        "*   Do not return any information about tables that do not contain financial information\n",
        "*   Data Presentation: Identify patterns like rows and columns (e.g., Role, Rate GBP/USD) and repeating elements (e.g., job titles and corresponding rates).\n",
        "*   Multi-page Tables: Check for consistency in headers and formatting across page breaks to identify tables spanning multiple pages. **If the table spans till the end of the page, examine the beginning of the following page to determine if it's a continuation of the same table.** If tables are spanning multiple pages they are still considered one single table with multiple page numbers in table_exists_on_pages.\n",
        "*   Continuation Clues:\n",
        "    *   **Page Break:** Check if the table is continued on the next page.\n",
        "    *   **Table Header:** Check if the table on the next page has a header row if not it may be a continuation of the same table.\n",
        "    *   **Formatting Consistency:** Look for consistent formatting (e.g., borders, font styles, column alignment) between the end of the previous page and the start of the next page.\n",
        "    *   **Content Flow:** Analyze if the content flows naturally from the previous page's table to the next page, indicating a continuation rather than a new table.\n",
        "*   Contextual Understanding:\n",
        "    *   Document Title and Introduction: Consider the document's title and any introductory information for clues about the types of rate structures expected.\n",
        "\n",
        "Table Format Description:\n",
        "*   **Table Start**: Identify the starting point of each table by recognizing patterns like:\n",
        "    *   **Keywords**: Look for keywords preceding tables such as \"Rate Card,\" \"Pricing Table,\" \"Fee Schedule,\" etc.\n",
        "    *   **Visual Cues**: Detect visual cues like lines, borders, or changes in font style/size that often mark the beginning of a table.\n",
        "*   **Table End**: Determine the end point of each table by identifying:\n",
        "    *   **Subsequent Content**: Look for changes in content or formatting that indicate the transition from table to non-table elements (e.g., paragraphs, headings).\n",
        "    *   **Last Row Value**: Extract the value of the first column in the final row of the table. This can help distinguish the table's end, especially in cases where formatting changes are subtle.\n",
        "*   **Structure**: Describe the overall structure of the table, including:\n",
        "    *   **Column Names**: Identify the names of all the columns in a certain table.\n",
        "    *   **Column Count**: Identify the total count of columns - do not take the rows into account.\n",
        "    *   **Rows Count**: Identify the number of rows.\n",
        "    *   **Headers**: Identify the presence of headers and their location (e.g., first row, first column).\n",
        "\n",
        "table_exists_on_pages : This is the document page number(s) where the tables exist so for example if the table starts on page 4 and ends on page 5 then table_exists_on_pages = [4,5]. This cannot be empty. This is extracted from the document's metadata not the page document printed. or shown in the document. Ensure that the table does not continue to the next page before assigning this value.\n",
        "first_page_table_appears: This is the document page number that the table starts on.\n",
        "last_page_table_appears: This is the document page number that the table ends on.\n",
        "\n",
        "\n",
        "\n",
        "If no tables are detected, return an empty JSON array: [].\n",
        "Output strictly in JSON format.\n",
        "\n",
        "Output Structure (Ensure strict valid JSON format. Do not use quotes within values):\n",
        "[\n",
        "  {\n",
        "    \"table_title\": \"APPENDIX 3-B1 (RATE CARD AND HOURLY RATES)\",\n",
        "    \"table_exists_on_pages\": \"[1,2]\",\n",
        "    \"first_page_table_appears\": 1,\n",
        "    \"last_page_table_appears\": 2,\n",
        "    \"Description\": \"This table appears to showcase the sales figures for different products across various regions and spans across 2 pages.\",\n",
        "    \"format\": {\n",
        "      \"start\": \"Starts after the heading: APPENDIX 3-B1 (RATE CARD AND HOURLY RATES)\",\n",
        "      \"end\": \"Ends before the page break\",\n",
        "      \"structure\": {\n",
        "        \"columns_names\": \"Column Names: product_name, region, rate\",\n",
        "        \"columns_count\": 3,\n",
        "        \"rows_count\": 11,\n",
        "        \"headers\": \"header row with bold text\"\n",
        "      },\n",
        "      \"last_row_first_column_value\": \"Junior Strategist\"\n",
        "    }\n",
        "  },\n",
        "  {\n",
        "    \"table_title\": \"Terms and Revenue\",\n",
        "    \"table_exists_on_pages\": \"[2]\",\n",
        "    \"first_page_table_appears\": 2,\n",
        "    \"last_page_table_appears\": 2,\n",
        "    \"Description\": \"This table appears in the bottom of the page to showcase the revenue of different products across various regions.\",\n",
        "    \"format\": {\n",
        "      \"start\": \"Starts after the heading: Terms and Revenue\",\n",
        "      \"end\": \"Ends before the page break\",\n",
        "      \"structure\": {\n",
        "        \"columns_names\": \"Column Names: product_name, price\",\n",
        "        \"columns_count\": 2,\n",
        "        \"rows_count\": 13,\n",
        "        \"headers\": \"header row with bold text\"\n",
        "      },\n",
        "      \"last_row_first_column_value\": \"Net Revenue\"\n",
        "    }\n",
        "  },\n",
        "  # ... (similar dictionaries for other tables) ...\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "def get_extraction_prompt(table_data, start, end):\n",
        "  return \"\"\"\n",
        "You are a business analyst that should extract data from a rate card table within a pdf document and output it as a specified structured schema.\n",
        "\n",
        "The pdf contains the following rate card table:\n",
        "\"\"\" + str(table_data) + \"\"\"\n",
        "You must extract the data from the rate card table only, ignoring any other tables and information. Do not include any additional explanations or text, and only output the JSON as shown in the hypothetical example output. Do not include any values, text, or data that are not explicitly found in the document.\n",
        "Begin table parsing and only consider data from after the \"start\" location above: \"\"\" + str(start) + \"\"\"\n",
        "End table parsing and do not consider any data after the \"end\" location above: \"\"\" + str(end) + \"\"\"\n",
        "Ignore any other tables or data that are not within these two locations, unless you encounter additional rows or columns that belong to the same table. Do not include thousands-separator commas in numerical values.\n",
        "Extract empty cells as null values and include this in the output.\n",
        "\n",
        "**Schema:**\n",
        "{\n",
        " \"Rate Card\": {\n",
        " \"type\": \"object\",\n",
        " \"properties\": {\n",
        "  \"Rate Card Category\": {\n",
        "  \"type\": \"string\",\n",
        "  \"description\": \"Overall rate card title / purpose / category\",\n",
        "  \"occurrence\": \"Optional Once\"\n",
        "  },\n",
        "  \"Rate Card Total Price\": {\n",
        "  \"type\": \"number\",\n",
        "  \"description\": \"Overall cost of the entire rate card, often presented at the end of the table as a total or summation\",\n",
        "  \"occurrence\": \"Optional Once\"\n",
        "  },\n",
        "  \"Line Item\": {\n",
        "  \"type\": \"array\",\n",
        "  \"items\": {\n",
        "   \"type\": \"object\",\n",
        "   \"properties\": {\n",
        "   \"Service\": {\n",
        "    \"type\": \"string\",\n",
        "    \"description\": \"The Service/Product that is being detailed and described in the rate line\",\n",
        "    \"occurrence\": \"Optional Once\"\n",
        "   },\n",
        "   \"Function\": {\n",
        "    \"type\": \"string\",\n",
        "    \"description\": \"Service function / detail - describes the specific instance, usage, or description of the service / product\",\n",
        "    \"occurrence\": \"Optional Once\"\n",
        "   },\n",
        "   \"Prices\": {\n",
        "    \"type\": \"array\",\n",
        "    \"price\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"Tier Category\": {\n",
        "          \"type\": \"string\",\n",
        "          \"description\": \"Top level tier category, in the case where a rate line has multiple prices for different tiers of the same item, for example due to different tiered pricing, different project types, or different categories. May be null if only a single tier.\",\n",
        "          \"occurrence\": \"Optional Once\"\n",
        "        },\n",
        "        \"Tier Subcategory\": {\n",
        "          \"type\": \"string\",\n",
        "          \"description\": \"Sub tier category to allow for 2nd level of tiered price structure (e.g. Standard - SD vs Standard - HD).\",\n",
        "          \"occurrence\": \"Optional Once\"\n",
        "        },\n",
        "        \"Cost per unit\": {\n",
        "          \"type\": \"number\",\n",
        "          \"description\": \"Cost or price of rate card line item, in number format with no commas\",\n",
        "          \"occurrence\": \"Optional Once\"\n",
        "        },\n",
        "           \"Location\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"Location / country / jurisdiction that the line item relates to.\",\n",
        "        \"occurrence\": \"Optional Once\"\n",
        "        },\n",
        "        \"Currency\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"Currency of the line item price.\",\n",
        "        \"occurrence\": \"Optional Once\"\n",
        "   },\n",
        "  }\n",
        "  }\n",
        "  },\n",
        "  \"Quantity or Unit\": {\n",
        "    \"type\": \"string\",\n",
        "    \"description\": \"Quantity of service/product that the rate card price is describing - This may be written in String format where only pure unit is specified, e.g. 'per license instance', or as a numerical value e.g. '4 FTEs'\",\n",
        "    \"occurrence\": \"Optional Once\"\n",
        "  },\n",
        "  \"Line Total Cost\": {\n",
        "    \"type\": \"number\",\n",
        "    \"description\": \"Total price for the whole line (will often be quantity * cost per unit, and is mostly relevant for larger rate cards)\",\n",
        "    \"occurrence\": \"Optional Once\"\n",
        "  }\n",
        "  }\n",
        "  }\n",
        "  }\n",
        " }\n",
        " }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "Example Output (Hypothetical):\n",
        "{\n",
        "\"Rate Card\": {\n",
        "\"Rate Card Category\": \"Personnel Rates for Unilever\",\n",
        "\"Line Item\": [\n",
        "{\n",
        "\"Service\": \"Car Rental\",\n",
        "\"Function\": \"Company car usage and rental\",\n",
        "\"Prices\": [\n",
        "{\n",
        "\"Cost per unit\": 400,\n",
        "\"Tier Category\": \"Bronze\",\n",
        "\"Currency\": \"SAR\"\n",
        "},\n",
        "{\n",
        "\"Cost per unit\": 500,\n",
        "\"Tier Category\": \"Silver\",\n",
        "\"Currency\": \"SAR\"\n",
        "}\n",
        "],\n",
        "\"Quantity or Unit\": \"per day\"\n",
        "},\n",
        "{\n",
        "\"Service\": \"Software Engineer\",\n",
        "\"Function\": \"Software development\",\n",
        "\"Prices\": [\n",
        "{\n",
        "\"Cost per unit\": 300,\n",
        "\"Tier Category\": \"Basic\",\n",
        "\"Currency\": \"GBP\"\n",
        "},\n",
        "{\n",
        "\"Cost per unit\": 900,\n",
        "\"Tier Category\": \"Advanced\",\n",
        "\"Currency\": \"GBP\"\n",
        "}\n",
        "],\n",
        "\"Quantity or Unit\": \"per FTE\"\n",
        "},\n",
        "{\n",
        "\"Service\": \"Laptops\",\n",
        "\"Function\": \"Hardware for use on project\",\n",
        "\"Prices\": [\n",
        "{\n",
        "\"Cost per unit\": 4500,\n",
        "\"Tier Category\": \"Project 1\",\n",
        "\"Tier Subcategory\": \"Simple\",\n",
        "\"Currency\": \"USD\"\n",
        "},\n",
        "{\n",
        "\"Cost per unit\": 6700,\n",
        "\"Tier Category\": \"Project 1\",\n",
        "\"Tier Subcategory\": \"Complex\",\n",
        "\"Currency\": \"USD\"\n",
        "}\n",
        "\n",
        "],\n",
        "\"Quantity or Unit\": \"1\"\n",
        "},\n",
        "]\n",
        "}\n",
        "}\n",
        "\n",
        "*Note the field \"Quantity or Unit\" is outside of the price array\n",
        "\n",
        "PDF Input:\n",
        "  \"\"\"\n",
        "\n",
        "def get_array_extraction_prompt(table_data):\n",
        "  start = table_data[\"format\"][\"start\"]\n",
        "  end = table_data[\"format\"][\"end\"]\n",
        "  return \"\"\"\n",
        "You are a business analyst that should extract data from a rate card table within a pdf document and output it as a specified structured schema.\n",
        "\n",
        "The pdf contains the following rate card table:\n",
        "\"\"\" + str(table_data) + \"\"\"\n",
        "You must extract the data from the rate card table only, ignoring any other tables and information. Do not include any additional explanations or text, and only output the JSON as shown in the hypothetical example output. Do not include any values, text, or data that are not explicitly found in the document.\n",
        "Begin table parsing and only consider data from after the \"start\" location above: \"\"\" + str(start) + \"\"\"\n",
        "End table parsing and do not consider any data after the \"end\" location above: \"\"\" + str(end) + \"\"\"\n",
        "Ignore any other tables or data that are not within these two locations, unless you encounter additional rows or columns that belong to the same table. Do not include thousands-separator commas in numerical values.\n",
        "This table has around \"\"\"+str(rows)+ \"\"\"rows.\n",
        "I would like to chunk this table into \"\"\"+str(rc_chunks)+\"\"\" chunks, return as an array of the start of the content of the first column for each of those chunks .\n",
        "Provide an answer that is grounded in the pdf with no hallucinations.Answer output is then formatted and presented as an array.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TgeGV0PlV5Yw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840400258,
          "user_tz": -60,
          "elapsed": 64,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions:\n",
        "\n",
        "Define helper functions for:\n",
        "- Metadata extraction\n",
        "- Document splitting\n",
        "- DocAI-based Processing\n",
        "- Gemini API Processing\n",
        "- JSON Parsing\n",
        "- Ground Truth Checks\n",
        "- BQ Upload\n"
      ],
      "metadata": {
        "id": "5dmpjFOBWqQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial Gemini Call to get the structure from the PDF\n",
        "def extract_pdf_content(pdf_path,prompt, temperature=1):\n",
        " #pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        " with open(pdf_path, \"rb\") as f:\n",
        "    pdf_file = Part.from_data(data=f.read(), mime_type=\"application/pdf\")\n",
        "\n",
        " generation_config = {\n",
        "   \"max_output_tokens\": 8192,\n",
        "   \"temperature\": temperature,\n",
        "   \"top_p\": 0.95,\n",
        " }\n",
        " content = [pdf_file, prompt]\n",
        " responses= model.generate_content(content, generation_config=generation_config)\n",
        " return responses.text\n",
        "\n",
        "def parse_json_from_gemini_output(output, filename, rate_card_index):\n",
        "  if output.startswith(\"```json\"):\n",
        "    start_marker = \"```json\"\n",
        "    end_marker = \"```\"\n",
        "    start_index = output.find(start_marker) + len(start_marker)\n",
        "    end_index = output.find(end_marker, start_index)\n",
        "    json_string = output[start_index:end_index].strip()\n",
        "  else:\n",
        "    json_string = output.strip()\n",
        "  json_string = json_string.replace('\\\\\"', '\"')  # Replace escaped quotes\n",
        "  json_string = json_string.replace(\"Quantity/Unit\",\"Quantity or Unit\")\n",
        "  extracted_json = json5.loads(json_string)\n",
        "  extracted_json[\"Rate Card\"][\"Contract ID\"] = filename\n",
        "  extracted_json[\"Rate Card\"][\"Rate Card Index\"] = rate_card_index\n",
        "  #upload_to_bq(extracted_json,\"rate_card_v1\")\n",
        "  return extracted_json\n",
        "\n",
        "def parse_json_from_markdown(markdown_text):\n",
        "  \"\"\"Extracts and parses JSON data from markdown code blocks, returning a list of dictionaries with extracted table information.\"\"\"\n",
        "  if markdown_text.startswith(\"```json\"):\n",
        "    start_marker = \"```json\"\n",
        "    end_marker = \"```\"\n",
        "    start_index = markdown_text.find(start_marker) + len(start_marker)\n",
        "    end_index = markdown_text.find(end_marker, start_index)\n",
        "    json_string = markdown_text[start_index:end_index].strip()\n",
        "  else:\n",
        "    json_string = markdown_text.strip()\n",
        "  json_string = json_string.replace('\\\\\"', '\"')  # Replace escaped quotes\n",
        "  table_data = json5.loads(json_string)\n",
        "\n",
        "  extracted_tables = []\n",
        "  rate_card_index = 1\n",
        "  for table in table_data:\n",
        "    extracted_table = {\n",
        "        \"rate_card_index\": rate_card_index,\n",
        "        \"table_title\": table[\"table_title\"],\n",
        "        \"table_exists_on_pages\": table[\"table_exists_on_pages\"],\n",
        "        \"first_page_table_appears\": table[\"first_page_table_appears\"],\n",
        "        \"last_page_table_appears\": table[\"last_page_table_appears\"],\n",
        "        \"description\": table[\"Description\"],\n",
        "        \"format\": {\n",
        "            \"start\": table[\"format\"][\"start\"],\n",
        "            \"end\": table[\"format\"][\"end\"],\n",
        "            \"structure\": table[\"format\"][\"structure\"],\n",
        "            \"last_row_first_column_value\": table[\"format\"][\"last_row_first_column_value\"],\n",
        "        },\n",
        "    }\n",
        "    extracted_tables.append(extracted_table)\n",
        "    rate_card_index += 1\n",
        "\n",
        "  return extracted_tables\n",
        "\n",
        "def check_for_ground_truth(filename, index):\n",
        "    client = bigquery.Client()\n",
        "    # Get max contract_id and iterate by 1\n",
        "    query = f\"\"\"\n",
        "        SELECT count(*) as row_count\n",
        "        FROM `{PROJECT_ID}.{DATASET_ID}.ground_truth`\n",
        "        WHERE `Rate Card`.`Contract ID` = '{filename}'\n",
        "        AND `Rate Card`.`Rate Card Index` = '{index}'\n",
        "    \"\"\"\n",
        "    query_job = client.query(query)\n",
        "    results = query_job.result()\n",
        "    for row in results:\n",
        "      if row[\"row_count\"] == 0:\n",
        "        return False\n",
        "      else:\n",
        "        return True\n",
        "\n",
        "def split_pdf_to_gcs(gcs_bucket_name, gcs_blob_name, parsed_data, gcs_output_bucket):\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(gcs_bucket_name)\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "\n",
        "    # Download PDF from GCS to a temporary local file\n",
        "    temp_pdf_file = f\"/tmp/{gcs_blob_name}\"\n",
        "    blob.download_to_filename(temp_pdf_file)\n",
        "\n",
        "    with open(temp_pdf_file, \"rb\") as f:\n",
        "        pdf_reader = PdfReader(f)\n",
        "\n",
        "        for table_data in parsed_data:\n",
        "            output_blob_name = f\"{table_data['rate_card_index']}.pdf\"\n",
        "            pdf_writer = PdfWriter()\n",
        "\n",
        "            # Handle page ranges correctly\n",
        "            if len(table_data['table_exists_on_pages']) == 1:\n",
        "                pdf_writer.add_page(pdf_reader.pages[0])\n",
        "            else:\n",
        "                for page_range in table_data['table_exists_on_pages'].strip('[]').split(','):\n",
        "                    if '-' in page_range:\n",
        "                        start, end = map(int, page_range.split('-'))\n",
        "                        for page_num in range(start, end+1):\n",
        "                            pdf_writer.add_page(pdf_reader.pages[page_num - 1])\n",
        "                    else:\n",
        "                        page_num = int(page_range)\n",
        "                        pdf_writer.add_page(pdf_reader.pages[page_num - 1])\n",
        "\n",
        "            # Write PDF to a BytesIO buffer\n",
        "            buffer = io.BytesIO()\n",
        "            pdf_writer.write(buffer)\n",
        "\n",
        "            # Upload buffer to GCS output bucket\n",
        "            output_bucket = storage_client.bucket(gcs_output_bucket)\n",
        "            output_blob = output_bucket.blob(output_blob_name)\n",
        "            buffer.seek(0)\n",
        "            output_blob.upload_from_file(buffer, content_type='application/pdf')\n",
        "            #print(\"Uploaded to GCS\")\n",
        "    # Delete the temporary local PDF file\n",
        "    os.remove(temp_pdf_file)\n",
        "\n",
        "def split_pdf_locally(pdf_path, parsed_data):\n",
        "\n",
        "  with open(pdf_path, \"rb\") as f:\n",
        "        pdf_reader = PdfReader(f)\n",
        "\n",
        "        for table_data in parsed_data:\n",
        "            output_blob_name = f\"{table_data['rate_card_index']}.pdf\"\n",
        "            pdf_writer = PdfWriter()\n",
        "\n",
        "            # Handle page ranges correctly\n",
        "            if len(table_data['table_exists_on_pages']) == 1:\n",
        "                pdf_writer.add_page(pdf_reader.pages[0])\n",
        "            else:\n",
        "                for page_range in table_data['table_exists_on_pages'].strip('[]').split(','):\n",
        "                    if '-' in page_range:\n",
        "                        start, end = map(int, page_range.split('-'))\n",
        "                        for page_num in range(start, end+1):\n",
        "                            pdf_writer.add_page(pdf_reader.pages[page_num - 1])\n",
        "                    else:\n",
        "                        page_num = int(page_range)\n",
        "                        pdf_writer.add_page(pdf_reader.pages[page_num - 1])\n",
        "\n",
        "            # Write PDF to a file\n",
        "            with open(output_blob_name, 'wb') as output_file:\n",
        "                pdf_writer.write(output_file)\n",
        "\n",
        "def extract_row_col(text):\n",
        "    \"\"\"Extracts the number of columns and rows from the structure text.\"\"\"\n",
        "    #pattern = r\"(\\d+) columns?, (\\d+) rows?\"\n",
        "    #match = re.search(pattern, text)\n",
        "    #if match:\n",
        "    #    columns, rows = match.groups()\n",
        "    #    return int(columns), int(rows)\n",
        "    #else:\n",
        "    #    return None, None\n",
        "    columns = text[\"columns_count\"]\n",
        "    rows = text[\"rows_count\"]\n",
        "    return int(columns), int(rows)\n",
        "\n",
        "def count_page_references(text):\n",
        "    \"\"\"Counts the number of page references within square brackets.\"\"\"\n",
        "    pattern = r\"\\[(\\d+(?:,\\d+)*)\\]\"  # Matches numbers and comma-separated numbers within brackets\n",
        "    match = re.findall(pattern, text)\n",
        "    if match:\n",
        "        return sum(len(ref.split(\",\")) for ref in match)  # Count individual numbers in each reference\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def empty_gcs_bucket(bucket_name):\n",
        "  \"\"\"Empties a Google Cloud Storage bucket.\n",
        "\n",
        "  Args:\n",
        "    bucket_name: Name of the bucket to empty.\n",
        "  \"\"\"\n",
        "  storage_client = storage.Client()\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "  # List blobs in the bucket\n",
        "  blobs = list(bucket.list_blobs())\n",
        "\n",
        "  # Delete each blob\n",
        "  for blob in blobs:\n",
        "    blob.delete()\n",
        "  #print(f\"Bucket {bucket_name} has been processsed successfully and now is emptied.\")\n",
        "\n",
        "\n",
        "def extract_pdf_content_stream(pdf_path,prompt,temperature=0.1):\n",
        " # pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        " with open(pdf_path, \"rb\") as f:\n",
        "    pdf_file = Part.from_data(data=f.read(), mime_type=\"application/pdf\")\n",
        "\n",
        "\n",
        " generation_config = {\n",
        "   \"max_output_tokens\": 8192,\n",
        "   \"temperature\": temperature,\n",
        "   \"top_p\": 0.95,\n",
        " }\n",
        " content = [pdf_file, prompt]\n",
        " responses= extraction_model.generate_content(content, generation_config=generation_config, stream = True)\n",
        " output = \"\"\n",
        " for response in responses:\n",
        "   output = output + response.text\n",
        "   print(response.text, end=\"\") #TODO: Do something with this data (e.g. store in BQ, output as a JSON to GCS)\n",
        " return output\n",
        "\n",
        "def extract_array_content(table_data, pdf_path, rc_chunks):\n",
        "\n",
        "  prompt = get_array_extraction_prompt(table_data)\n",
        "  #pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        "  with open(pdf_path, \"rb\") as f:\n",
        "    pdf_file = Part.from_data(data=f.read(), mime_type=\"application/pdf\")\n",
        "\n",
        "\n",
        "  generation_config = {\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"temperature\": temperature,\n",
        "    \"top_p\": 0.95,\n",
        "  }\n",
        "  content = [pdf_file, prompt]\n",
        "  responses= extraction_model.generate_content(content, generation_config=generation_config)\n",
        "  return responses.text\n"
      ],
      "metadata": {
        "id": "yUOIdnwbXSVV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840990675,
          "user_tz": -60,
          "elapsed": 59,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Extraction\n",
        "\n",
        "#### File Selection & Metadata Extraction"
      ],
      "metadata": {
        "id": "1xHe_bpnX2DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"Sample-SoW.pdf\"\n",
        "\n",
        "max_retries = 5\n",
        "retry_count = 0\n",
        "parsed_data = None\n",
        "\n",
        "while retry_count < max_retries and parsed_data is None:\n",
        "   try:\n",
        "     if (retry_count >= 3):\n",
        "       temperature = 1.25\n",
        "     else:\n",
        "       temperature = 0.8\n",
        "\n",
        "     answer = extract_pdf_content(pdf_path, structure_prompt, temperature)\n",
        "     print(\"Gemini's Extracted Structure:\", answer)\n",
        "     parsed_data = parse_json_from_markdown(answer)\n",
        "     print(\"Found \" + str(len(parsed_data)) + \" rate card tables\")\n",
        "   except Exception as e:\n",
        "     print(f\"Error during parsing: {e}\")\n",
        "     retry_count += 1\n",
        "     time.sleep(5)\n",
        "\n",
        "if parsed_data is None:\n",
        "   print(\"Failed to parse data even after all retries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCweEXtCX_Er",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840598320,
          "user_tz": -60,
          "elapsed": 6729,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8d757cf9-9fec-4950-aca7-aeab40e40d0d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini's Extracted Structure: ```json\n",
            "[\n",
            "  {\n",
            "    \"table_title\": null,\n",
            "    \"table_exists_on_pages\": [\n",
            "      7\n",
            "    ],\n",
            "    \"first_page_table_appears\": 7,\n",
            "    \"last_page_table_appears\": 7,\n",
            "    \"Description\": \"This table represents a rate card outlining the cost breakdown for a project, detailing roles, applicable day rates, estimated man-days, discounts, and subtotals.\",\n",
            "    \"format\": {\n",
            "      \"start\": \"Starts before the heading: X Fixed Price\",\n",
            "      \"end\": \"Ends after the row with values: Price  € 2,082.00\",\n",
            "      \"structure\": {\n",
            "        \"columns_names\": \"Class, Role Description, Name of the person\\n(not mandatory), Location, Applicable Day Rate in agreed currency, Estimated Mandays, Discount (%), Sub Total\",\n",
            "        \"columns_count\": 8,\n",
            "        \"rows_count\": 2,\n",
            "        \"headers\": \"header row with bold text\"\n",
            "      },\n",
            "      \"last_row_first_column_value\": \"Price\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Found 1 rate card tables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split document for each rate card"
      ],
      "metadata": {
        "id": "l2WjS0jPcqut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty_gcs_bucket(\"processing-rate-cards\")\n",
        "# gcs_output_bucket = \"processing-rate-cards\"\n",
        "# split_pdf_to_gcs(gcs_bucket_name, gcs_blob_name, parsed_data, gcs_output_bucket)\n",
        "split_pdf_locally(pdf_path, parsed_data)\n",
        "\n",
        "print(\"Split PDF files have been generated for each rate card\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5lBB_Xqc0U-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718840996320,
          "user_tz": -60,
          "elapsed": 136,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d564fd73-df71-48aa-81f1-b58d12aeba13"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split PDF files have been generated for each rate card\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_retries = 5\n",
        "retry_count = 0\n",
        "output = None\n",
        "filename = pdf_path\n",
        "\n",
        "outputs = []\n",
        "for table_info in parsed_data:\n",
        "    output = None\n",
        "    structure = table_info['format']['structure']\n",
        "    title = table_info['table_title']\n",
        "    index = table_info['rate_card_index']\n",
        "    columns, rows = extract_row_col(structure)\n",
        "    page_refs = table_info['table_exists_on_pages']\n",
        "    # num_pages = count_page_references(page_refs)\n",
        "    # print(f\"Columns: {columns}, Rows: {rows} , Number of pages: {num_pages} , title = {title}.pdf\" )\n",
        "    try:\n",
        "      file_path = str(index)+\".pdf\"\n",
        "    except:\n",
        "      file_path = \"None.pdf\"\n",
        "    print(\"Extracting rate card table \" + str(index))\n",
        "    file_path = \"gs://processing_rate_cards/\"+file_path\n",
        "    # Changes done here\n",
        "    if rows>=25:\n",
        "      print(\"Chunking Needed\")\n",
        "      rc_chunks = (rows -1) // 21 # chunking for every twenty rows\n",
        "      array= extract_array_content(table_info, pdf_path, rc_chunks)\n",
        "      start_marker = \"```json\"\n",
        "      end_marker = \"```\"\n",
        "      start_index = array.find(start_marker) + len(start_marker)\n",
        "      end_index = array.find(end_marker, start_index)\n",
        "      array_json_string = array[start_index:end_index].strip()\n",
        "      array_json_string = json5.loads(array_json_string)\n",
        "      start = table_info[\"format\"][\"start\"]\n",
        "      end = table_info[\"format\"][\"end\"]\n",
        "      array_json_string.append(end)\n",
        "      array_json_string[0] =start\n",
        "      print(array_json_string)\n",
        "      for i in range(len(array_json_string) -1):\n",
        "        start = array_json_string[i]\n",
        "        end=array_json_string[i+1]\n",
        "        prompt = get_extraction_prompt(table_info,start,end)\n",
        "        while retry_count < max_retries and output is None:\n",
        "          try:\n",
        "            if (retry_count >= 3):\n",
        "              temperature = 0.5\n",
        "            else:\n",
        "              temperature = 0.1\n",
        "            output = extract_pdf_content_stream(pdf_path, prompt, temperature)\n",
        "            parsed_json_output = parse_json_from_gemini_output(output,gcs_blob_name,index)\n",
        "            # outputs.append(parsed_json_output)\n",
        "            # #print()\n",
        "            # print(json.dumps(parsed_json_output, indent=4))\n",
        "            # print(\"Extraction complete\")\n",
        "          except Exception as e:\n",
        "            print(f\"Error during parsing: {e}\")\n",
        "            retry_count += 1\n",
        "            time.sleep(5)\n",
        "          if parsed_data is None:\n",
        "            print(\"Failed to parse data even after all retries.\")\n",
        "\n",
        "    else:\n",
        "      print(\"normal process\")\n",
        "      start = table_info[\"format\"][\"start\"]\n",
        "      end = table_info[\"format\"][\"end\"]\n",
        "      prompt = get_extraction_prompt(table_info,start,end)\n",
        "      while retry_count < max_retries and output is None:\n",
        "        try:\n",
        "          if (retry_count >= 3):\n",
        "            temperature = 0.5\n",
        "          else:\n",
        "            temperature = 0.1\n",
        "          output = extract_pdf_content_stream(pdf_path, prompt, temperature)\n",
        "          parsed_json_output = parse_json_from_gemini_output(output,filename,index)\n",
        "          outputs.append(parsed_json_output)\n",
        "          #print()\n",
        "          print(json.dumps(parsed_json_output, indent=4))\n",
        "          print(\"Extraction complete\")\n",
        "        except Exception as e:\n",
        "          print(f\"Error during parsing: {e}\")\n",
        "          retry_count += 1\n",
        "          time.sleep(5)\n",
        "        if parsed_data is None:\n",
        "          print(\"Failed to parse data even after all retries.\")\n",
        "\n",
        "      print(\"Processed Table:\")\n",
        "      print(parsed_json_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFKUZSEZc6np",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718841180607,
          "user_tz": -60,
          "elapsed": 5118,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "81bb913c-0bd0-4988-fd9d-972e819f7c1b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting rate card table 1\n",
            "normal process\n",
            "```json\n",
            "{\n",
            " \"Rate Card\": {\n",
            "  \"Rate Card Category\": \"X Fixed Price\",\n",
            "  \"Rate Card Total Price\": 2082.00,\n",
            "  \"Line Item\": [\n",
            "   {\n",
            "    \"Service\": null,\n",
            "    \"Function\": null,\n",
            "    \"Prices\": [\n",
            "     {\n",
            "      \"Tier Category\": null,\n",
            "      \"Tier Subcategory\": null,\n",
            "      \"Cost per unit\": 694,\n",
            "      \"Location\": \"Ireland,\\nItaly,\\nIndia\",\n",
            "      \"Currency\": \"€\"\n",
            "     }\n",
            "    ],\n",
            "    \"Quantity or Unit\": \"3\",\n",
            "    \"Line Total Cost\": 2082.00\n",
            "   }\n",
            "  ]\n",
            " }\n",
            "}\n",
            "```{\n",
            "    \"Rate Card\": {\n",
            "        \"Rate Card Category\": \"X Fixed Price\",\n",
            "        \"Rate Card Total Price\": 2082.0,\n",
            "        \"Line Item\": [\n",
            "            {\n",
            "                \"Service\": null,\n",
            "                \"Function\": null,\n",
            "                \"Prices\": [\n",
            "                    {\n",
            "                        \"Tier Category\": null,\n",
            "                        \"Tier Subcategory\": null,\n",
            "                        \"Cost per unit\": 694,\n",
            "                        \"Location\": \"Ireland,\\nItaly,\\nIndia\",\n",
            "                        \"Currency\": \"\\u20ac\"\n",
            "                    }\n",
            "                ],\n",
            "                \"Quantity or Unit\": \"3\",\n",
            "                \"Line Total Cost\": 2082.0\n",
            "            }\n",
            "        ],\n",
            "        \"Contract ID\": \"Sample-SoW.pdf\",\n",
            "        \"Rate Card Index\": 1\n",
            "    }\n",
            "}\n",
            "Extraction complete\n",
            "Processed Table:\n",
            "{'Rate Card': {'Rate Card Category': 'X Fixed Price', 'Rate Card Total Price': 2082.0, 'Line Item': [{'Service': None, 'Function': None, 'Prices': [{'Tier Category': None, 'Tier Subcategory': None, 'Cost per unit': 694, 'Location': 'Ireland,\\nItaly,\\nIndia', 'Currency': '€'}], 'Quantity or Unit': '3', 'Line Total Cost': 2082.0}], 'Contract ID': 'Sample-SoW.pdf', 'Rate Card Index': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Options to improve detection\n",
        "\n",
        "Increase Resolution of the image:"
      ],
      "metadata": {
        "id": "qTeELQaCw1jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines the Generative Models Configuration\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 0.95,\n",
        "}\n",
        "\n",
        "# Loading Gemini Pro Vision Model\n",
        "multimodal_model = GenerativeModel(\n",
        "    \"gemini-1.5-pro-001\", generation_config=generation_config\n",
        ")\n",
        "\n",
        "def split_pdf_extract_data(pdfList, folder_uri):\n",
        "    # To get better resolution\n",
        "    zoom_x = 4.0  # horizontal zoom\n",
        "    zoom_y = 4.0  # vertical zoom\n",
        "    mat = fitz.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
        "\n",
        "    for indiv_Pdf in pdfList:\n",
        "        doc = fitz.open(indiv_Pdf)  # open document\n",
        "        for page in doc:  # iterate through the pages\n",
        "            pix = page.get_pixmap(matrix=mat)  # render page to an image\n",
        "            outpath = f\"{folder_uri}{indiv_Pdf}_{page.number}.png\"\n",
        "            pix.save(outpath)  # store image as a PNG\n",
        "\n",
        "    # Define the path where images are located\n",
        "    image_names = os.listdir(folder_uri)\n",
        "    Max_images = len(image_names)\n",
        "\n",
        "    # Create empty lists to store image information\n",
        "    page_source = []\n",
        "    page_content = []\n",
        "    page_id = []\n",
        "\n",
        "    p_id = 0  # Initialize image ID counter\n",
        "    rest_count = 0  # Initialize counter for error handling\n",
        "\n",
        "    while p_id < Max_images:\n",
        "        try:\n",
        "            # Construct the full path to the current image\n",
        "            image_path = folder_uri + image_names[p_id]\n",
        "\n",
        "            # Load the image\n",
        "            image = Image.load_from_file(image_path)\n",
        "\n",
        "            # Generate prompts for text and table extraction\n",
        "            prompt_text = \"Extract all text content in the image\"\n",
        "            prompt_table = (\n",
        "                \"Detect table in this image. Extract content maintaining the structure\"\n",
        "            )\n",
        "            prompt_image = \"Detect images in this image. Extract content in the form of alternative text or subtitles to each sub-image\"\n",
        "\n",
        "            # Extract text using your multimodal model\n",
        "            contents = [image, prompt_text]\n",
        "            response = multimodal_model.generate_content(contents)\n",
        "            text_content = response.text\n",
        "\n",
        "            # Extract table using your multimodal model\n",
        "            contents = [image, prompt_table]\n",
        "            response = multimodal_model.generate_content(contents)\n",
        "            table_content = response.text\n",
        "\n",
        "            # Extract information from images (i.e. Subtitle / Alternative text). | Currently Disabled\n",
        "            # contents = [image, prompt_image]\n",
        "            # response = multimodal_model.generate_content(contents)\n",
        "            # image_content = response.text\n",
        "\n",
        "            # Log progress and store results\n",
        "            print(f\"processed image no: {p_id}\")\n",
        "            page_source.append(image_path)\n",
        "            page_content.append(\n",
        "                text_content + \"\\n\" + table_content\n",
        "            )  # + \"\\n\" + image_content)\n",
        "            page_id.append(p_id)\n",
        "            p_id += 1\n",
        "\n",
        "        except Exception as err:\n",
        "            # Handle errors during processing\n",
        "            print(err)\n",
        "            print(\"Taking Some Rest\")\n",
        "            time.sleep(\n",
        "                12\n",
        "            )  # Pause execution for 12 second due to default Quota for Vertex\n",
        "            rest_count += 1\n",
        "            if rest_count == 5:  # Limit consecutive error handling\n",
        "                rest_count = 0\n",
        "                print(f\"Cannot process image no: {image_path}\")\n",
        "                p_id += 1  # Move to the next image\n",
        "\n",
        "    # Create a DataFrame to store extracted information\n",
        "    df = pd.DataFrame(\n",
        "        {\"page_id\": page_id, \"page_source\": page_source, \"page_content\": page_content}\n",
        "    )\n",
        "    del page_id, page_source, page_content  # Conserve memory\n",
        "    df.head()  # Preview the DataFrame\n",
        "\n",
        "    return df\n",
        "\n",
        "my_list_pdfs = [\"rate_card_02.png\"]\n",
        "my_folder_url = \"./images/\"\n",
        "\n",
        "upgraded_pdf = split_pdf_extract_data(my_list_pdfs, my_folder_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7pG-ouayl-J",
        "outputId": "1161c418-89de-437b-af27-59034197d374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 21] Is a directory: 'images/.ipynb_checkpoints'\n",
            "Taking Some Rest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipeline_constants"
      },
      "source": [
        "# Vertex AI Pipelines\n",
        "\n",
        "Setup up the following constants for Vertex AI Pipelines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg_0ZGc0WRPB"
      },
      "outputs": [],
      "source": [
        "PIPELINE_ROOT = \"{}/pipeline_root/control\".format(BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk"
      },
      "source": [
        "## Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF5ycPqrWRPB"
      },
      "outputs": [],
      "source": [
        "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "define_component:coin"
      },
      "source": [
        "## Define pipeline components\n",
        "\n",
        "The following example defines three simple pipeline components:\n",
        "\n",
        "- A component that process the pdf documents.\n",
        "(Note: This component requires an `import json` in the component function definition)\n",
        "- A component that gets the relevant ground truth for each extracted table\n",
        "- A component that leverages the extracted output as well as the ground truth to compute accuracy, precission, recall and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo2jtxnlWRPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718707122422,
          "user_tz": -60,
          "elapsed": 336,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3ac553d9-f787-4e2a-b064-78c2e2d15090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-ebb3f3ce2795>:1: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  @dsl.component(\n",
            "<ipython-input-35-ebb3f3ce2795>:6: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  def contract_import() -> list:\n",
            "<ipython-input-35-ebb3f3ce2795>:18: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  @component (\n",
            "<ipython-input-35-ebb3f3ce2795>:28: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  def table_details_extraction(document: str) -> list:\n",
            "<ipython-input-35-ebb3f3ce2795>:195: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  @dsl.component(\n",
            "<ipython-input-35-ebb3f3ce2795>:204: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  def table_import(doc_tables: list, document: str) -> list:\n",
            "<ipython-input-35-ebb3f3ce2795>:282: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  @dsl.component(\n",
            "<ipython-input-35-ebb3f3ce2795>:294: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  def process_table(table: dict, document: str) -> dict:\n",
            "<ipython-input-35-ebb3f3ce2795>:567: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  @dsl.component(\n",
            "<ipython-input-35-ebb3f3ce2795>:577: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  def get_table_ground_truth(table: dict, document: str) -> dict:\n",
            "<ipython-input-35-ebb3f3ce2795>:626: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  @dsl.component(\n",
            "<ipython-input-35-ebb3f3ce2795>:631: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n",
            "  def compute_accuracy(extracted_data: dict, ground_truth: dict, metrics: Output[Metrics]) -> dict: #None:\n"
          ]
        }
      ],
      "source": [
        "@dsl.component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\"google-cloud-storage\"],\n",
        "    output_component_file=\"contract_import.yaml\"\n",
        ")\n",
        "def contract_import() -> list:\n",
        "    # Fetching contract from gcs\n",
        "    from google.cloud import storage\n",
        "    storage_client = storage.Client()\n",
        "    contracts = []\n",
        "    blobs = storage_client.list_blobs(\"ratecards-eval-gen-ai-sandbox-unique\")\n",
        "    for blob in blobs:\n",
        "        if blob.name.endswith(\".pdf\") and not \"/\" in blob.name:\n",
        "            print(blob.name)\n",
        "            contracts.append(blob.name)\n",
        "    return contracts\n",
        "\n",
        "@component (\n",
        "    base_image=\"python:3.9\",  # Ensure Python 3.9 for consistency\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-aiplatform\",\n",
        "        \"vertexai\",\n",
        "        \"google-cloud-storage\",\n",
        "        \"json5\"\n",
        "        ],\n",
        "    output_component_file=\"table_details_extraction.yaml\",\n",
        ")\n",
        "def table_details_extraction(document: str) -> list:\n",
        "    # Imports needed for this function\n",
        "    import json5\n",
        "    import time\n",
        "    import vertexai\n",
        "    from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "    import vertexai.preview.generative_models as generative_models\n",
        "    from google.cloud import storage\n",
        "\n",
        "    PROJECT_ID =\"gen-ai-sandbox\"\n",
        "    LOCATION = \"us-central1\"\n",
        "    # Prompts\n",
        "    #########\n",
        "    structure_prompt= \"\"\"Objective: Accurately identify all tables within the provided PDF document, and extract formatting details for full reliable table boundary detection. The output must be a strictly valid JSON format.**Avoid using double quotes within values; instead, use single quotes or escape them.**\n",
        "\n",
        "    Instructions:\n",
        "\n",
        "    Table Recognition:\n",
        "    *   Data Presentation: Identify patterns like rows and columns (e.g., Role, Rate GBP/USD) and repeating elements (e.g., job titles and corresponding rates).\n",
        "    *   Multi-page Tables: Check for consistency in headers and formatting across page breaks to identify tables spanning multiple pages. **If the table spans till the end of the page, examine the beginning of the following page to determine if it's a continuation of the same table.** If tables are spanning multiple pages they are still considered one single table with multiple page numbers in table_exists_on_pages.\n",
        "    *   Continuation Clues:\n",
        "        *   **Page Break:** Check if the table is continued on the next page.\n",
        "        *   **Table Header:** Check if the table on the next page has a header row if not it may be a continuation of the same table.\n",
        "        *   **Formatting Consistency:** Look for consistent formatting (e.g., borders, font styles, column alignment) between the end of the previous page and the start of the next page.\n",
        "        *   **Content Flow:** Analyze if the content flows naturally from the previous page's table to the next page, indicating a continuation rather than a new table.\n",
        "    *   Contextual Understanding:\n",
        "        *   Document Title and Introduction: Consider the document's title and any introductory information for clues about the types of rate structures expected.\n",
        "\n",
        "    Table Format Description:\n",
        "    *   **Table Start**: Identify the starting point of each table by recognizing patterns like:\n",
        "        *   **Keywords**: Look for keywords preceding tables such as \"Rate Card,\" \"Pricing Table,\" \"Fee Schedule,\" etc.\n",
        "        *   **Visual Cues**: Detect visual cues like lines, borders, or changes in font style/size that often mark the beginning of a table.\n",
        "    *   **Table End**: Determine the end point of each table by identifying:\n",
        "        *   **Subsequent Content**: Look for changes in content or formatting that indicate the transition from table to non-table elements (e.g., paragraphs, headings).\n",
        "        *   **Last Row Value**: Extract the value of the first column in the final row of the table. This can help distinguish the table's end, especially in cases where formatting changes are subtle.\n",
        "    *   **Structure**: Describe the overall structure of the table, including:\n",
        "        *   Number of columns and rows.\n",
        "        *   Presence of headers and their location (e.g., first row, first column).\n",
        "        *   Any specific formatting patterns (e.g., alternating row colors, bold text for headers).\n",
        "\n",
        "    table_exists_on_pages : This is the document page number(s) where the tables exist so for example if the table starts on page 4 and ends on page 5 then table_exists_on_pages = [4,5]. This cannot be empty. This is extracted from the document's metadata not the page document printed. or shown in the document. Ensure that the table does not continue to the next page before assigning this value.\n",
        "\n",
        "    If no tables are detected, return an empty JSON array: [].\n",
        "\n",
        "    Output Structure (Ensure strict valid JSON format. Do not use quotes within values):\n",
        "    [\n",
        "      {\n",
        "        \"table_title\": \"APPENDIX 3-B1 (RATE CARD AND HOURLY RATES)\",\n",
        "        \"table_exists_on_pages\": \"[1,2]\",\n",
        "        \"Description\": \"This table appears to showcase the sales figures for different products across various regions and spans across 2 pages.\",\n",
        "        \"format\": {\n",
        "          \"start\": \"Starts after the heading: APPENDIX 3-B1 (RATE CARD AND HOURLY RATES)\",\n",
        "          \"end\": \"Ends before the page break\",\n",
        "          \"structure\": \"3 columns, 11 rows, header row with bold text\",\n",
        "          \"last_row_first_column_value\": \"Junior Strategist\"\n",
        "        }\n",
        "      },\n",
        "      {\n",
        "        \"table_title\": \"Terms and Revenue\",\n",
        "        \"table_exists_on_pages\": \"[2]\",\n",
        "        \"Description\": \"This table appears in the bottom of the page to showcase the revenue of different products across various regions.\",\n",
        "        \"format\": {\n",
        "          \"start\": \"Starts after the heading: Terms and Revenue\",\n",
        "          \"end\": \"Ends before the page break\",\n",
        "          \"structure\": \"2 columns, 13 rows, header row with bold text\",\n",
        "          \"last_row_first_column_value\": \"Net Revenue\"\n",
        "        }\n",
        "      },\n",
        "      # ... (similar dictionaries for other tables) ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "\n",
        "    # Vertex AI Initialisation\n",
        "    #########################\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    model = GenerativeModel(\"gemini-experimental\")\n",
        "    extraction_model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "\n",
        "    #Initial Gemini Call to get the structure from the PDF\n",
        "    def extract_pdf_content(pdf_path,prompt, temperature=1):\n",
        "      pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        "      generation_config = {\n",
        "        \"max_output_tokens\": 8192,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": 0.95,\n",
        "      }\n",
        "      content = [pdf_file, prompt]\n",
        "      responses= model.generate_content(content, generation_config=generation_config)\n",
        "      return responses.text\n",
        "\n",
        "    def parse_json_from_markdown(markdown_text):\n",
        "        \"\"\"Extracts and parses JSON data from markdown code blocks, returning a list of dictionaries with extracted table information.\"\"\"\n",
        "        start_marker = \"```json\"\n",
        "        end_marker = \"```\"\n",
        "        start_index = markdown_text.find(start_marker) + len(start_marker)\n",
        "        end_index = markdown_text.find(end_marker, start_index)\n",
        "        json_string = markdown_text[start_index:end_index].strip()\n",
        "        json_string = json_string.replace('\\\\\"', '\"')  # Replace escaped quotes\n",
        "        table_data = json5.loads(json_string)\n",
        "\n",
        "        extracted_tables = []\n",
        "        rate_card_index = 1\n",
        "        for table in table_data:\n",
        "            extracted_table = {\n",
        "                \"rate_card_index\": rate_card_index,\n",
        "                \"table_title\": table[\"table_title\"],\n",
        "                \"table_exists_on_pages\": table[\"table_exists_on_pages\"],\n",
        "                \"description\": table[\"Description\"],\n",
        "                \"format\": {\n",
        "                    \"start\": table[\"format\"][\"start\"],\n",
        "                    \"end\": table[\"format\"][\"end\"],\n",
        "                    \"structure\": table[\"format\"][\"structure\"],\n",
        "                    \"last_row_first_column_value\": table[\"format\"][\"last_row_first_column_value\"],\n",
        "                },\n",
        "            }\n",
        "            extracted_tables.append(extracted_table)\n",
        "            rate_card_index += 1\n",
        "        return extracted_tables\n",
        "\n",
        "    #Set file path / Can be later automatically triggers by GCS changes in a Function\n",
        "    gcs_bucket_name = \"ratecards-eval-gen-ai-sandbox-unique\"\n",
        "\n",
        "    # Input to the step - contract name:\n",
        "    #gcs_blob_name = \"gemini_test_01.pdf\"\n",
        "    gcs_blob_name = document\n",
        "\n",
        "    pdf_path = f\"gs://{gcs_bucket_name}/{gcs_blob_name}\"\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    parsed_data = None\n",
        "    while retry_count < max_retries and parsed_data is None:\n",
        "        try:\n",
        "            if (retry_count >= 3):\n",
        "                temperature = 1.25\n",
        "            else:\n",
        "                temperature = 1\n",
        "\n",
        "            answer = extract_pdf_content(pdf_path, structure_prompt, temperature)\n",
        "            print(\"Gemini's Extracted Structure:\", answer)\n",
        "            parsed_data = parse_json_from_markdown(answer)\n",
        "            print(\"Found \" + str(len(parsed_data)) + \" rate card tables\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during parsing: {e}\")\n",
        "            retry_count += 1\n",
        "            time.sleep(5)\n",
        "\n",
        "        if parsed_data is None:\n",
        "            raise RuntimeError(\"Failed to extract data after retries\")\n",
        "\n",
        "    #return json.dumps(parsed_data, sort_keys=True)\n",
        "    print(parsed_data)\n",
        "    return parsed_data\n",
        "\n",
        "@component\n",
        "def doc_table_ground_truth_import(document: str) -> str:\n",
        "    # Fetching contract from gcs\n",
        "    contract = \"tables info (JSON format)\"\n",
        "\n",
        "    return \"success\"\n",
        "\n",
        "@component\n",
        "def table_details_extraction_evaluation(document: list, ground_truth: str) -> str:\n",
        "    # To be replaced with table details evaluation function\n",
        "    tables = \"tables info (JSON format)\"\n",
        "    ground_truth = \"Ground truth data from BigQuery (JSON format)\"\n",
        "    return \"success\"\n",
        "\n",
        "@dsl.component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"PyPDF2\",\n",
        "        \"google-cloud-storage\",\n",
        "        \"google-cloud-aiplatform\",\n",
        "    ],\n",
        "    output_component_file=\"table_import.yaml\"\n",
        ")\n",
        "def table_import(doc_tables: list, document: str) -> list:\n",
        "    # This function creates temporary PDF files with the specific pages relating to a rate card\n",
        "    from PyPDF2 import PdfReader, PdfWriter\n",
        "    from google.cloud import storage\n",
        "    import io\n",
        "    import os\n",
        "\n",
        "    def empty_gcs_bucket(bucket_name):\n",
        "        \"\"\"Empties a Google Cloud Storage bucket.\n",
        "\n",
        "        Args:\n",
        "          bucket_name: Name of the bucket to empty.\n",
        "        \"\"\"\n",
        "        storage_client = storage.Client()\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "        # List blobs in the bucket\n",
        "        blobs = list(bucket.list_blobs())\n",
        "\n",
        "        # Delete each blob\n",
        "        for blob in blobs:\n",
        "            blob.delete()\n",
        "\n",
        "        print(f\"Bucket {bucket_name} has been processsed successfully and now is emptied.\")\n",
        "\n",
        "    def split_pdf_to_gcs(gcs_bucket_name, gcs_blob_name, parsed_data, gcs_output_bucket):\n",
        "        storage_client = storage.Client()\n",
        "        bucket = storage_client.bucket(gcs_bucket_name)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "\n",
        "        # Download PDF from GCS to a temporary local file\n",
        "        temp_pdf_file = f\"/tmp/{gcs_blob_name}\"\n",
        "        blob.download_to_filename(temp_pdf_file)\n",
        "\n",
        "        with open(temp_pdf_file, \"rb\") as f:\n",
        "            pdf_reader = PdfReader(f)\n",
        "\n",
        "            for table_data in parsed_data:\n",
        "                output_blob_name = f\"{table_data['rate_card_index']}.pdf\"\n",
        "                pdf_writer = PdfWriter()\n",
        "\n",
        "                # Handle page ranges correctly\n",
        "                for page_range in table_data['table_exists_on_pages'].strip('[]').split(','):\n",
        "                    if '-' in page_range:\n",
        "                        start, end = map(int, page_range.split('-'))\n",
        "                        for page_num in range(start, end+1):\n",
        "                            pdf_writer.add_page(pdf_reader.pages[page_num - 1])\n",
        "                    else:\n",
        "                        page_num = int(page_range)\n",
        "                        pdf_writer.add_page(pdf_reader.pages[page_num - 1])\n",
        "\n",
        "                # Write PDF to a BytesIO buffer\n",
        "                buffer = io.BytesIO()\n",
        "                pdf_writer.write(buffer)\n",
        "\n",
        "                # Upload buffer to GCS output bucket\n",
        "                output_bucket = storage_client.bucket(gcs_output_bucket)\n",
        "                output_blob = output_bucket.blob(output_blob_name)\n",
        "                buffer.seek(0)\n",
        "                output_blob.upload_from_file(buffer, content_type='application/pdf')\n",
        "                print(\"Uploaded to GCS\")\n",
        "        # Delete the temporary local PDF file\n",
        "        os.remove(temp_pdf_file)\n",
        "\n",
        "    empty_gcs_bucket(\"processing-rate-cards\")\n",
        "    gcs_output_bucket = \"processing-rate-cards\"\n",
        "    gcs_bucket_name = \"ratecards-eval-gen-ai-sandbox-unique\"\n",
        "    gcs_blob_name = document\n",
        "    parsed_data = doc_tables\n",
        "    split_pdf_to_gcs(gcs_bucket_name, gcs_blob_name, parsed_data, gcs_output_bucket)\n",
        "    print(\"Split PDF files have been generated for each rate card\")\n",
        "\n",
        "    # Listing all tables within doc\n",
        "    for table in doc_tables:\n",
        "        print(table)\n",
        "\n",
        "    return doc_tables\n",
        "\n",
        "@dsl.component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-storage\",\n",
        "        \"google-cloud-documentai\",\n",
        "        \"json5\",\n",
        "        \"google-cloud-aiplatform\",\n",
        "        \"vertexai\",\n",
        "        \"google-api-core\",\n",
        "    ],\n",
        "    output_component_file=\"process_table.yaml\"\n",
        ")\n",
        "def process_table(table: dict, document: str) -> dict:\n",
        "    # Tabular data extraction process\n",
        "    import json\n",
        "    import io\n",
        "    import json5\n",
        "    import os\n",
        "    import re\n",
        "    import time\n",
        "    from google.cloud import storage\n",
        "    from google.api_core.client_options import ClientOptions\n",
        "    from google.cloud import documentai as docai\n",
        "    from typing import Optional, Sequence, MutableSequence, Tuple\n",
        "    from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    output = None\n",
        "    parsed_json_output = None\n",
        "    mime_type = \"application/pdf\"\n",
        "    table_info = table\n",
        "    gcs_bucket_name = \"ratecards-eval-gen-ai-sandbox-unique\"\n",
        "    gcs_blob_name = document\n",
        "    pdf_path = f\"gs://{gcs_bucket_name}/{gcs_blob_name}\"\n",
        "\n",
        "    def extract_row_col(text):\n",
        "        \"\"\"Extracts the number of columns and rows from the structure text.\"\"\"\n",
        "        pattern = r\"(\\d+) columns?, (\\d+) rows?\"\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            columns, rows = match.groups()\n",
        "            return int(columns), int(rows)\n",
        "        else:\n",
        "            return None, None\n",
        "    def count_page_references(text):\n",
        "        \"\"\"Counts the number of page references within square brackets.\"\"\"\n",
        "        pattern = r\"\\[(\\d+(?:,\\d+)*)\\]\"  # Matches numbers and comma-separated numbers within brackets\n",
        "        match = re.findall(pattern, text)\n",
        "        if match:\n",
        "            return sum(len(ref.split(\",\")) for ref in match)  # Count individual numbers in each reference\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def get_extraction_prompt(table_data):\n",
        "        start = table_data[\"format\"][\"start\"]\n",
        "        end = table_data[\"format\"][\"end\"]\n",
        "        prompt = \"\"\"\n",
        "          You are a business analyst that should extract data from a rate card table within a pdf document and output it as a specified structured schema.\n",
        "\n",
        "          The pdf contains the following rate card table:\n",
        "          \"\"\" + str(table_data) + \"\"\"\n",
        "          You must extract the data from the rate card table only, ignoring any other tables and information. Do not include any additional explanations or text, and only output the JSON as shown in the hypothetical example output. Do not include any values, text, or data that are not explicitly found in the document.\n",
        "          Begin table parsing and only consider data from after the \"start\" location above: \"\"\" + str(start) + \"\"\"\n",
        "          End table parsing and do not consider any data after the \"end\" location above: \"\"\" + str(end) + \"\"\"\n",
        "          Ignore any other tables or data that are not within these two locations, unless you encounter additional rows or columns that belong to the same table.\n",
        "\n",
        "          **Schema:**\n",
        "          {\n",
        "          \"Rate Card\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {\n",
        "            \"Rate Card Category\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Overall rate card title / purpose / category\",\n",
        "            \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Rate Card Total Price\": {\n",
        "            \"type\": \"number\",\n",
        "            \"description\": \"Overall cost of the entire rate card, often presented at the end of the table as a total or summation\",\n",
        "            \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Line Item\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "            \"Service\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"The Service/Product that is being detailed and described in the rate line\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Function\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Service function / detail - describes the specific instance, usage, or description of the service / product\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Prices\": {\n",
        "              \"type\": \"array\",\n",
        "              \"price\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                  \"Tier Category\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Top level tier category, in the case where a rate line has multiple prices for different tiers of the same item, for example due to different tiered pricing, different project types, or different categories. May be null if only a single tier.\",\n",
        "                    \"occurrence\": \"Optional Once\"\n",
        "                  },\n",
        "                  \"Tier Subcategory\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Sub tier category to allow for 2nd level of tiered price structure (e.g. Standard - SD vs Standard - HD).\",\n",
        "                    \"occurrence\": \"Optional Once\"\n",
        "                  },\n",
        "                  \"Cost per unit\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"Cost or price of rate card line item\",\n",
        "                    \"occurrence\": \"Optional Once\"\n",
        "                  }\n",
        "                }\n",
        "              }\n",
        "              },\n",
        "            \"Quantity/Unit\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Quantity of service/product that the rate card price is describing - This may be written in String format where only pure unit is specified, e.g. 'per license instance', or as a numerical value e.g. '4 FTEs'\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Currency\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Currency of the line item price.\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Location\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Location / country / jurisdiction that the line item relates to.\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Line Total Cost\": {\n",
        "              \"type\": \"number\",\n",
        "              \"description\": \"Total price for the whole line (will often be quantity * cost per unit, and is mostly relevant for larger rate cards)\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            }\n",
        "            }\n",
        "            }\n",
        "            }\n",
        "          }\n",
        "          }\n",
        "          }\n",
        "\n",
        "\n",
        "\n",
        "          Example Output (Hypothetical):\n",
        "          {\n",
        "          \"Rate Card\": {\n",
        "          \"Category\": \"Personnel Rates for Unilever\",\n",
        "          \"Line Item\": [\n",
        "          {\n",
        "          \"Service\": \"Car Rental\",\n",
        "          \"Function\": \"Company car usage and rental\",\n",
        "          \"Prices\": [\n",
        "          {\n",
        "          \"Cost per unit\": 400,\n",
        "          \"Tier Category\": \"Bronze\"\n",
        "          },\n",
        "          {\n",
        "          \"Cost per unit\": 500,\n",
        "          \"Tier Category\": \"Silver\"\n",
        "          }\n",
        "          ],\n",
        "          \"Currency\": \"SAR\",\n",
        "          \"Quantity/Unit\": \"per day\"\n",
        "          },\n",
        "          {\n",
        "          \"Service\": \"Software Engineer\",\n",
        "          \"Function\": \"Software development\",\n",
        "          \"Prices\": [\n",
        "          {\n",
        "          \"Cost per unit\": 300,\n",
        "          \"Tier Category\": \"Basic\"\n",
        "          },\n",
        "          {\n",
        "          \"Cost per unit\": 900,\n",
        "          \"Tier Category\": \"Advanced\"\n",
        "          }\n",
        "          ],\n",
        "          \"Currency\": \"GBP\",\n",
        "          \"Quantity/Unit\": \"per FTE\"\n",
        "          },\n",
        "          {\n",
        "          \"Service\": \"Laptops\",\n",
        "          \"Function\": \"Hardware for use on project\",\n",
        "          \"Prices\": [\n",
        "          {\n",
        "          \"Cost per unit\": 4500,\n",
        "          \"Tier Category\": \"Project 1\"\n",
        "          \"Tier Subcategory\": \"Simple\"\n",
        "          },\n",
        "          {\n",
        "          \"Cost per unit\": 6700,\n",
        "          \"Tier Category\": \"Project 1\"\n",
        "          \"Tier Subcategory\": \"Complex\"\n",
        "          }\n",
        "\n",
        "          ],\n",
        "          \"Currency\": \"USD\",\n",
        "          \"Quantity/Unit\": \"1\"\n",
        "          },\n",
        "\n",
        "          ]\n",
        "          }\n",
        "          }\n",
        "\n",
        "          PDF Input:\n",
        "        \"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def extract_pdf_content_stream(pdf_path,prompt, temperature=0.1):\n",
        "        pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        "        generation_config = {\n",
        "          \"max_output_tokens\": 8192,\n",
        "          \"temperature\": temperature,\n",
        "          \"top_p\": 0.95,\n",
        "        }\n",
        "        content = [pdf_file, prompt]\n",
        "        extraction_model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "        responses= extraction_model.generate_content(content, generation_config=generation_config, stream = True)\n",
        "        output = \"\"\n",
        "        for response in responses:\n",
        "          output = output + response.text\n",
        "          print(response.text, end=\"\") #TODO: Do something with this data (e.g. store in BQ, output as a JSON to GCS)\n",
        "        return output\n",
        "\n",
        "    def parse_json_from_gemini_output(output, filename, rate_card_index):\n",
        "        start_marker = \"```json\"\n",
        "        end_marker = \"```\"\n",
        "        start_index = output.find(start_marker) + len(start_marker)\n",
        "        end_index = output.find(end_marker, start_index)\n",
        "        json_string = output[start_index:end_index].strip()\n",
        "        json_string = json_string.replace('\\\\\"', '\"')  # Replace escaped quotes\n",
        "        json_string = json_string.replace(\"Quantity/Unit\",\"Quantity or Unit\")\n",
        "        extracted_json = json5.loads(json_string)\n",
        "        extracted_json[\"Rate Card\"][\"Contract ID\"] = filename\n",
        "        extracted_json[\"Rate Card\"][\"Rate Card Index\"] = rate_card_index\n",
        "        with open('data.json', 'w') as f:\n",
        "            json.dump(extracted_json, f)\n",
        "        #upload_to_bq(extracted_json,\"rate_card\")\n",
        "        return extracted_json\n",
        "\n",
        "    structure = table['format']['structure']\n",
        "    title = table['table_title']\n",
        "    index = table['rate_card_index']\n",
        "    columns, rows = extract_row_col(structure)\n",
        "    page_refs = table['table_exists_on_pages']\n",
        "    num_pages = count_page_references(page_refs)\n",
        "    print(f\"Columns: {columns}, Rows: {rows} , Number of pages: {num_pages} , title = {title}.pdf\" )\n",
        "    try:\n",
        "        file_path = str(index)+\".pdf\"\n",
        "    except:\n",
        "        file_path = \"None.pdf\"\n",
        "    print(file_path)\n",
        "    #if (columns < 3 and rows < 10 and num_pages == 1): -- send to DocAI\n",
        "    if 1==1:\n",
        "        print(\"Send to Gemini\")\n",
        "        print(\"Extracting rate card table \" + str(index))\n",
        "        prompt = get_extraction_prompt(table_info)\n",
        "        file_path = \"gs://processing-rate-cards/\"+file_path\n",
        "        while retry_count < max_retries and output is None:\n",
        "            try:\n",
        "                if (retry_count >= 3):\n",
        "                    temperature = 0.5\n",
        "                else:\n",
        "                    temperature = 0.1\n",
        "                output = extract_pdf_content_stream(pdf_path, prompt, temperature)\n",
        "                parsed_json_output = parse_json_from_gemini_output(output,gcs_blob_name,index)\n",
        "                print(\"Extraction complete\")\n",
        "            except Exception as e:\n",
        "              print(f\"Error during parsing: {e}\")\n",
        "              retry_count += 1\n",
        "              time.sleep(5)\n",
        "        if parsed_json_output is None:\n",
        "            raise RuntimeError(\"Failed to extract data after retries\")\n",
        "\n",
        "    # return json.dumps(parsed_json_output, sort_keys=True)\n",
        "    print(\"Processed Table:\")\n",
        "    print(parsed_json_output)\n",
        "    return parsed_json_output\n",
        "\n",
        "@dsl.component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-bigquery\",\n",
        "        \"pandas\",\n",
        "        \"db-dtypes\",\n",
        "        \"numpy\",\n",
        "        ],\n",
        "    output_component_file=\"get_table_ground_truth.yaml\"\n",
        ")\n",
        "def get_table_ground_truth(table: dict, document: str) -> dict:\n",
        "    \"\"\"\n",
        "    Reads ground truth data from BigQuery based on the provided table ID.\n",
        "    \"\"\"\n",
        "    from google.cloud import bigquery\n",
        "    import pandas\n",
        "    import numpy as np\n",
        "\n",
        "    gcs_blob_name = document\n",
        "\n",
        "    client = bigquery.Client(project=\"gen-ai-sandbox\") #, dataset=\"go_reply_extracted_contract_data\")\n",
        "    # Construct the query based on the contract ID\n",
        "    query = f\"\"\"SELECT *\n",
        "        FROM `ratecard_extraction.extracted_ratecards`\n",
        "        WHERE `Rate Card`.`Contract ID` = '{gcs_blob_name}' ;\n",
        "        \"\"\"\n",
        "\n",
        "    # Set the contract ID as a query parameter\n",
        "    query_job = client.query(query)\n",
        "    # Get the results as a dictionary\n",
        "    results = query_job.result()\n",
        "    query_job = client.query(query)\n",
        "    records = [dict(row) for row in query_job]\n",
        "\n",
        "    '''\n",
        "    results = query_job.result()\n",
        "    df = results.to_dataframe()\n",
        "    first_row = df.iloc[0]\n",
        "\n",
        "    # Function to convert ndarrays within a dictionary structure\n",
        "    def convert_ndarrays_to_dicts(data):\n",
        "        if isinstance(data, np.ndarray):\n",
        "            # Handle ndarrays (specifically the \"Prices\" key)\n",
        "            if data.dtype == object:  # Check for object dtype (nested ndarrays)\n",
        "                return [dict(item) for item in data]  # Convert each row to a dictionary\n",
        "            else:\n",
        "                return data.tolist()  # Convert other ndarrays to lists\n",
        "        elif isinstance(data, dict):\n",
        "            return {key: convert_ndarrays_to_dicts(value) for key, value in data.items()}\n",
        "        else:\n",
        "            return data\n",
        "\n",
        "    # Apply the recursive conversion function\n",
        "    ground_truth = convert_ndarrays_to_dicts(first_row.to_dict())\n",
        "    print(ground_truth)\n",
        "    '''\n",
        "\n",
        "    return records[0]\n",
        "\n",
        "@dsl.component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\"numpy\"],\n",
        "    output_component_file=\"evaluation.yaml\"\n",
        ")\n",
        "def compute_accuracy(extracted_data: dict, ground_truth: dict, metrics: Output[Metrics]) -> dict: #None:\n",
        "    def extract_services(table):\n",
        "        return set(\n",
        "            (item['Service'], price['Cost per unit']) # , item['Function']\n",
        "            for item in table['Rate Card']['Line Item']\n",
        "            for price in item['Prices']\n",
        "        )\n",
        "\n",
        "    services_1 = extract_services(extracted_data)\n",
        "    services_2 = extract_services(ground_truth)\n",
        "\n",
        "    # Calculating true positives, false positives, and false negatives\n",
        "    true_positives = services_1 & services_2\n",
        "    false_positives = services_1 - services_2\n",
        "    false_negatives = services_2 - services_1\n",
        "\n",
        "    # Calculating precision, recall, and F1 score\n",
        "    precision = len(true_positives) / (len(true_positives) + len(false_positives)) if (len(true_positives) + len(false_positives)) > 0 else 0\n",
        "    recall = len(true_positives) / (len(true_positives) + len(false_negatives)) if (len(true_positives) + len(false_negatives)) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    Metrics.log_metric(metrics, \"Precision\", precision)\n",
        "    Metrics.log_metric(metrics, \"Recall\", recall)\n",
        "    Metrics.log_metric(metrics, \"F1 Score\", f1_score)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "define_pipeline:control"
      },
      "source": [
        "## Define a pipeline that uses control structures\n",
        "\n",
        "The following example defines a pipeline that uses these components and demonstrates the use of  `dsl.Condition` and `dsl.ParallelFor`.\n",
        "\n",
        "The `json_string` input's default value is a nested JSON list converted to a string. As the pipeline definition shows, the loop and conditional expressions are able to process this string as a list, and access list items and sub-items.\n",
        "The same holds for the list output by the `args_generator_op`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP-SAqLiWRPB"
      },
      "outputs": [],
      "source": [
        "@dsl.pipeline(\n",
        "    name=\"control\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "def evaluate_data_extraction(): #gcs_path: str, document_id: str, project_id: str):\n",
        "    \"\"\"\n",
        "    Pipeline to evaluate data extraction accuracy using LLM and Gemini API.\n",
        "    \"\"\"\n",
        "\n",
        "    contract = contract_import()\n",
        "\n",
        "    with dsl.ParallelFor(items=contract.output) as contract_title:\n",
        "        table_details_extraction_result = table_details_extraction(document= contract_title)\n",
        "        doc_table_ground_truth = doc_table_ground_truth_import(document= contract_title)\n",
        "        table_details_extraction_evaluation(document=table_details_extraction_result.output, ground_truth=doc_table_ground_truth.output)\n",
        "\n",
        "        tables = table_import(doc_tables= table_details_extraction_result.output, document=contract_title)\n",
        "        with dsl.ParallelFor(items=tables.output) as table:\n",
        "          extracted_data = process_table(table = table, document=contract_title)\n",
        "          table_ground_truth = get_table_ground_truth(table = table, document=contract_title)\n",
        "          compute_accuracy(extracted_data=extracted_data.output , ground_truth = table_ground_truth.output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "compile_pipeline"
      },
      "source": [
        "## Compile the pipeline\n",
        "\n",
        "Next, compile the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBAfW6OlWRPE"
      },
      "outputs": [],
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=evaluate_data_extraction, package_path=\"control_pipeline.yaml\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_pipeline:control"
      },
      "source": [
        "## Run the pipeline\n",
        "\n",
        "Next, run the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlo7aV8OWRPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718707146099,
          "user_tz": -60,
          "elapsed": 14877,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3a11cd26-6723-4c16-86a5-0748b27af4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/230294883006/locations/us-central1/pipelineJobs/control-20240618103851\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/230294883006/locations/us-central1/pipelineJobs/control-20240618103851')\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/control-20240618103851?project=230294883006\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/230294883006/locations/us-central1/pipelineJobs/control-20240618103851 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/230294883006/locations/us-central1/pipelineJobs/control-20240618103851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'control_pipeline.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "DISPLAY_NAME = \"control\"\n",
        "\n",
        "job = aip.PipelineJob(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    template_path=\"control_pipeline.yaml\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "\n",
        "job.run()\n",
        "\n",
        "! rm control_pipeline.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view_pipeline_run:control"
      },
      "source": [
        "Click on the generated link to see your run in the Cloud Console.\n",
        "\n",
        "<!-- It should look something like this as it is running:\n",
        "\n",
        "<a href=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" width=\"40%\"/></a> -->\n",
        "\n",
        "*In the Google Cloud Console, many of the pipeline DAG nodes expand or collapse when you click on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup:pipelines"
      },
      "source": [
        "# Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can delete the individual resources you created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7gODO9HWRPF"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "\n",
        "#delete_bucket = False\n",
        "\n",
        "#job.delete()\n",
        "\n",
        "#if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "#    ! gsutil rm -r $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ."
      ],
      "metadata": {
        "id": "3B6a-M3ogZE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "Wu3WJcvQgZPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "uth7Pv3VgZZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".\n"
      ],
      "metadata": {
        "id": "E-knNPemgZhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Ground Truth Generation Script..."
      ],
      "metadata": {
        "id": "WDu7teeqgOXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def table_details_extraction(document: str) -> list:\n",
        "    # Imports needed for this function\n",
        "    import json\n",
        "    import time\n",
        "    import vertexai\n",
        "    from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "    import vertexai.preview.generative_models as generative_models\n",
        "    from google.cloud import storage\n",
        "\n",
        "    PROJECT_ID =\"gen-ai-sandbox\"\n",
        "    LOCATION = \"us-central1\"\n",
        "    # Prompts\n",
        "    #########\n",
        "    structure_prompt= \"\"\"Objective: Accurately identify all tables within the provided PDF document, and extract formatting details for full reliable table boundary detection. The output must be a strictly valid JSON format.**Avoid using double quotes within values; instead, use single quotes or escape them.**\n",
        "\n",
        "    Instructions:\n",
        "\n",
        "    Table Recognition:\n",
        "    *   Data Presentation: Identify patterns like rows and columns (e.g., Role, Rate GBP/USD) and repeating elements (e.g., job titles and corresponding rates).\n",
        "    *   Multi-page Tables: Check for consistency in headers and formatting across page breaks to identify tables spanning multiple pages. **If the table spans till the end of the page, examine the beginning of the following page to determine if it's a continuation of the same table.** If tables are spanning multiple pages they are still considered one single table with multiple page numbers in table_exists_on_pages.\n",
        "    *   Continuation Clues:\n",
        "        *   **Page Break:** Check if the table is continued on the next page.\n",
        "        *   **Table Header:** Check if the table on the next page has a header row if not it may be a continuation of the same table.\n",
        "        *   **Formatting Consistency:** Look for consistent formatting (e.g., borders, font styles, column alignment) between the end of the previous page and the start of the next page.\n",
        "        *   **Content Flow:** Analyze if the content flows naturally from the previous page's table to the next page, indicating a continuation rather than a new table.\n",
        "    *   Contextual Understanding:\n",
        "        *   Document Title and Introduction: Consider the document's title and any introductory information for clues about the types of rate structures expected.\n",
        "\n",
        "    Table Format Description:\n",
        "    *   **Table Start**: Identify the starting point of each table by recognizing patterns like:\n",
        "        *   **Keywords**: Look for keywords preceding tables such as \"Rate Card,\" \"Pricing Table,\" \"Fee Schedule,\" etc.\n",
        "        *   **Visual Cues**: Detect visual cues like lines, borders, or changes in font style/size that often mark the beginning of a table.\n",
        "    *   **Table End**: Determine the end point of each table by identifying:\n",
        "        *   **Subsequent Content**: Look for changes in content or formatting that indicate the transition from table to non-table elements (e.g., paragraphs, headings).\n",
        "        *   **Last Row Value**: Extract the value of the first column in the final row of the table. This can help distinguish the table's end, especially in cases where formatting changes are subtle.\n",
        "    *   **Structure**: Describe the overall structure of the table, including:\n",
        "        *   Number of columns and rows.\n",
        "        *   Presence of headers and their location (e.g., first row, first column).\n",
        "        *   Any specific formatting patterns (e.g., alternating row colors, bold text for headers).\n",
        "\n",
        "    table_exists_on_pages : This is the document page number(s) where the tables exist so for example if the table starts on page 4 and ends on page 5 then table_exists_on_pages = [4,5]. This cannot be empty. This is extracted from the document's metadata not the page document printed. or shown in the document. Ensure that the table does not continue to the next page before assigning this value.\n",
        "\n",
        "    If no tables are detected, return an empty JSON array: [].\n",
        "\n",
        "    Output Structure (Ensure strict valid JSON format. Do not use quotes within values):\n",
        "    [\n",
        "      {\n",
        "        \"table_title\": \"APPENDIX 3-B1 (RATE CARD AND HOURLY RATES)\",\n",
        "        \"table_exists_on_pages\": \"[1,2]\",\n",
        "        \"Description\": \"This table appears to showcase the sales figures for different products across various regions and spans across 2 pages.\",\n",
        "        \"format\": {\n",
        "          \"start\": \"Starts after the heading: APPENDIX 3-B1 (RATE CARD AND HOURLY RATES)\",\n",
        "          \"end\": \"Ends before the page break\",\n",
        "          \"structure\": \"3 columns, 11 rows, header row with bold text\",\n",
        "          \"last_row_first_column_value\": \"Junior Strategist\"\n",
        "        }\n",
        "      },\n",
        "      {\n",
        "        \"table_title\": \"Terms and Revenue\",\n",
        "        \"table_exists_on_pages\": \"[2]\",\n",
        "        \"Description\": \"This table appears in the bottom of the page to showcase the revenue of different products across various regions.\",\n",
        "        \"format\": {\n",
        "          \"start\": \"Starts after the heading: Terms and Revenue\",\n",
        "          \"end\": \"Ends before the page break\",\n",
        "          \"structure\": \"2 columns, 13 rows, header row with bold text\",\n",
        "          \"last_row_first_column_value\": \"Net Revenue\"\n",
        "        }\n",
        "      },\n",
        "      # ... (similar dictionaries for other tables) ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "\n",
        "    # Vertex AI Initialisation\n",
        "    #########################\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    model = GenerativeModel(\"gemini-experimental\")\n",
        "    extraction_model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "\n",
        "    #Initial Gemini Call to get the structure from the PDF\n",
        "    def extract_pdf_content(pdf_path,prompt, temperature=1):\n",
        "      pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        "      generation_config = {\n",
        "        \"max_output_tokens\": 8192,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": 0.95,\n",
        "      }\n",
        "      content = [pdf_file, prompt]\n",
        "      responses= model.generate_content(content, generation_config=generation_config)\n",
        "      return responses.text\n",
        "\n",
        "    def parse_json_from_markdown(markdown_text):\n",
        "        \"\"\"Extracts and parses JSON data from markdown code blocks, returning a list of dictionaries with extracted table information.\"\"\"\n",
        "        start_marker = \"```json\"\n",
        "        end_marker = \"```\"\n",
        "        start_index = markdown_text.find(start_marker) + len(start_marker)\n",
        "        end_index = markdown_text.find(end_marker, start_index)\n",
        "        json_string = markdown_text[start_index:end_index].strip()\n",
        "        json_string = json_string.replace('\\\\\"', '\"')  # Replace escaped quotes\n",
        "        table_data = json.loads(json_string)\n",
        "\n",
        "        extracted_tables = []\n",
        "        rate_card_index = 1\n",
        "        for table in table_data:\n",
        "            extracted_table = {\n",
        "                \"rate_card_index\": rate_card_index,\n",
        "                \"table_title\": table[\"table_title\"],\n",
        "                \"table_exists_on_pages\": table[\"table_exists_on_pages\"],\n",
        "                \"description\": table[\"Description\"],\n",
        "                \"format\": {\n",
        "                    \"start\": table[\"format\"][\"start\"],\n",
        "                    \"end\": table[\"format\"][\"end\"],\n",
        "                    \"structure\": table[\"format\"][\"structure\"],\n",
        "                    \"last_row_first_column_value\": table[\"format\"][\"last_row_first_column_value\"],\n",
        "                },\n",
        "            }\n",
        "            extracted_tables.append(extracted_table)\n",
        "            rate_card_index += 1\n",
        "        return extracted_tables\n",
        "\n",
        "    #Set file path / Can be later automatically triggers by GCS changes in a Function\n",
        "    gcs_bucket_name = \"ratecards-eval-gen-ai-sandbox-unique\"\n",
        "\n",
        "    # Input to the step - contract name:\n",
        "    #gcs_blob_name = \"gemini_test_01.pdf\"\n",
        "    gcs_blob_name = document\n",
        "\n",
        "    pdf_path = f\"gs://{gcs_bucket_name}/{gcs_blob_name}\"\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    parsed_data = None\n",
        "    while retry_count < max_retries and parsed_data is None:\n",
        "        try:\n",
        "            if (retry_count >= 3):\n",
        "                temperature = 1.25\n",
        "            else:\n",
        "                temperature = 1\n",
        "\n",
        "            answer = extract_pdf_content(pdf_path, structure_prompt, temperature)\n",
        "            print(\"Gemini's Extracted Structure:\", answer)\n",
        "            parsed_data = parse_json_from_markdown(answer)\n",
        "            print(\"Found \" + str(len(parsed_data)) + \" rate card tables\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during parsing: {e}\")\n",
        "            retry_count += 1\n",
        "            time.sleep(5)\n",
        "\n",
        "        if parsed_data is None:\n",
        "            raise RuntimeError(\"Failed to extract data after retries\")\n",
        "\n",
        "    #return json.dumps(parsed_data, sort_keys=True)\n",
        "    print(parsed_data)\n",
        "    return parsed_data\n",
        "\n",
        "table_details_extraction(\"rate01.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tio9tKz_jyCw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715159705580,
          "user_tz": -60,
          "elapsed": 9290,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e78b76f2-ce68-43be-fd96-d6aa4b246988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini's Extracted Structure: ```json\n",
            "[\n",
            "  {\n",
            "    \"table_title\": \"Worldwide Production Hourly Rates (USD)\",\n",
            "    \"table_exists_on_pages\": \"[1]\",\n",
            "    \"Description\": \"This table presents hourly rates for various digital production services, categorized into Creative Development, Project Management, Technology & Digital Studio, Data Management, and Programming.\",\n",
            "    \"format\": {\n",
            "      \"start\": \"Starts after the heading: Worldwide Production Hourly Rates (USD)\",\n",
            "      \"end\": \"Ends before the page break\",\n",
            "      \"structure\": \"2 columns, 24 rows, header row with bold text\",\n",
            "      \"last_row_first_column_value\": \"XML/WAP Programming\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Found 1 rate card tables\n",
            "[{'rate_card_index': 1, 'table_title': 'Worldwide Production Hourly Rates (USD)', 'table_exists_on_pages': '[1]', 'description': 'This table presents hourly rates for various digital production services, categorized into Creative Development, Project Management, Technology & Digital Studio, Data Management, and Programming.', 'format': {'start': 'Starts after the heading: Worldwide Production Hourly Rates (USD)', 'end': 'Ends before the page break', 'structure': '2 columns, 24 rows, header row with bold text', 'last_row_first_column_value': 'XML/WAP Programming'}}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rate_card_index': 1,\n",
              "  'table_title': 'Worldwide Production Hourly Rates (USD)',\n",
              "  'table_exists_on_pages': '[1]',\n",
              "  'description': 'This table presents hourly rates for various digital production services, categorized into Creative Development, Project Management, Technology & Digital Studio, Data Management, and Programming.',\n",
              "  'format': {'start': 'Starts after the heading: Worldwide Production Hourly Rates (USD)',\n",
              "   'end': 'Ends before the page break',\n",
              "   'structure': '2 columns, 24 rows, header row with bold text',\n",
              "   'last_row_first_column_value': 'XML/WAP Programming'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = {'rate_card_index': 1,\n",
        "  'table_title': 'Worldwide Production Hourly Rates (USD)',\n",
        "  'table_exists_on_pages': '[1]',\n",
        "  'description': 'This table provides hourly rates for various digital production services. It includes categories for Creative Development, Project Management, Technology & Digital Studio, Data Management, and Programming.',\n",
        "  'format': {'start': 'Starts after the heading: Worldwide Production Hourly Rates (USD)',\n",
        "   'end': 'Ends before the next section or page break',\n",
        "   'structure': '2 columns, 19 rows, header row with bold text',\n",
        "   'last_row_first_column_value': 'XML/WAP Programming'}}\n",
        "\n",
        "def process_table(table: dict, document: str) -> dict:\n",
        "    # Tabular data extraction process\n",
        "    import json\n",
        "    import io\n",
        "    import json\n",
        "    import os\n",
        "    import re\n",
        "    import time\n",
        "    from google.cloud import storage\n",
        "    from google.api_core.client_options import ClientOptions\n",
        "    #from google.cloud import documentai as docai\n",
        "    from typing import Optional, Sequence, MutableSequence, Tuple\n",
        "    from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    output = None\n",
        "    parsed_json_output = None\n",
        "    mime_type = \"application/pdf\"\n",
        "    table_info = table\n",
        "    gcs_bucket_name = \"ratecards-eval-gen-ai-sandbox-unique\"\n",
        "    gcs_blob_name = document\n",
        "    pdf_path = f\"gs://{gcs_bucket_name}/{gcs_blob_name}\"\n",
        "\n",
        "    def extract_row_col(text):\n",
        "        \"\"\"Extracts the number of columns and rows from the structure text.\"\"\"\n",
        "        pattern = r\"(\\d+) columns?, (\\d+) rows?\"\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            columns, rows = match.groups()\n",
        "            return int(columns), int(rows)\n",
        "        else:\n",
        "            return None, None\n",
        "    def count_page_references(text):\n",
        "        \"\"\"Counts the number of page references within square brackets.\"\"\"\n",
        "        pattern = r\"\\[(\\d+(?:,\\d+)*)\\]\"  # Matches numbers and comma-separated numbers within brackets\n",
        "        match = re.findall(pattern, text)\n",
        "        if match:\n",
        "            return sum(len(ref.split(\",\")) for ref in match)  # Count individual numbers in each reference\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def get_extraction_prompt(table_data):\n",
        "        start = table_data[\"format\"][\"start\"]\n",
        "        end = table_data[\"format\"][\"end\"]\n",
        "        prompt = \"\"\"\n",
        "          You are a business analyst that should extract data from a rate card table within a pdf document and output it as a specified structured schema.\n",
        "\n",
        "          The pdf contains the following rate card table:\n",
        "          \"\"\" + str(table_data) + \"\"\"\n",
        "          You must extract the data from the rate card table only, ignoring any other tables and information. Do not include any additional explanations or text, and only output the JSON as shown in the hypothetical example output. Do not include any values, text, or data that are not explicitly found in the document.\n",
        "          Begin table parsing and only consider data from after the \"start\" location above: \"\"\" + str(start) + \"\"\"\n",
        "          End table parsing and do not consider any data after the \"end\" location above: \"\"\" + str(end) + \"\"\"\n",
        "          Ignore any other tables or data that are not within these two locations, unless you encounter additional rows or columns that belong to the same table.\n",
        "\n",
        "          **Schema:**\n",
        "          {\n",
        "          \"Rate Card\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {\n",
        "            \"Rate Card Category\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Overall rate card title / purpose / category\",\n",
        "            \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Rate Card Total Price\": {\n",
        "            \"type\": \"number\",\n",
        "            \"description\": \"Overall cost of the entire rate card, often presented at the end of the table as a total or summation\",\n",
        "            \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Line Item\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "            \"Service\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"The Service/Product that is being detailed and described in the rate line\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Function\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Service function / detail - describes the specific instance, usage, or description of the service / product\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Prices\": {\n",
        "              \"type\": \"array\",\n",
        "              \"price\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                  \"Tier Category\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Top level tier category, in the case where a rate line has multiple prices for different tiers of the same item, for example due to different tiered pricing, different project types, or different categories. May be null if only a single tier.\",\n",
        "                    \"occurrence\": \"Optional Once\"\n",
        "                  },\n",
        "                  \"Tier Subcategory\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Sub tier category to allow for 2nd level of tiered price structure (e.g. Standard - SD vs Standard - HD).\",\n",
        "                    \"occurrence\": \"Optional Once\"\n",
        "                  },\n",
        "                  \"Cost per unit\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"Cost or price of rate card line item\",\n",
        "                    \"occurrence\": \"Optional Once\"\n",
        "                  }\n",
        "                }\n",
        "              }\n",
        "              },\n",
        "            \"Quantity/Unit\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Quantity of service/product that the rate card price is describing - This may be written in String format where only pure unit is specified, e.g. 'per license instance', or as a numerical value e.g. '4 FTEs'\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Currency\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Currency of the line item price.\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Location\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Location / country / jurisdiction that the line item relates to.\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            },\n",
        "            \"Line Total Cost\": {\n",
        "              \"type\": \"number\",\n",
        "              \"description\": \"Total price for the whole line (will often be quantity * cost per unit, and is mostly relevant for larger rate cards)\",\n",
        "              \"occurrence\": \"Optional Once\"\n",
        "            }\n",
        "            }\n",
        "            }\n",
        "            }\n",
        "          }\n",
        "          }\n",
        "          }\n",
        "\n",
        "\n",
        "\n",
        "          Example Output (Hypothetical):\n",
        "          {\n",
        "          \"Rate Card\": {\n",
        "          \"Category\": \"Personnel Rates for Unilever\",\n",
        "          \"Line Item\": [\n",
        "          {\n",
        "          \"Service\": \"Car Rental\",\n",
        "          \"Function\": \"Company car usage and rental\",\n",
        "          \"Prices\": [\n",
        "          {\n",
        "          \"Cost per unit\": 400,\n",
        "          \"Tier Category\": \"Bronze\"\n",
        "          },\n",
        "          {\n",
        "          \"Cost per unit\": 500,\n",
        "          \"Tier Category\": \"Silver\"\n",
        "          }\n",
        "          ],\n",
        "          \"Currency\": \"SAR\",\n",
        "          \"Quantity/Unit\": \"per day\"\n",
        "          },\n",
        "          {\n",
        "          \"Service\": \"Software Engineer\",\n",
        "          \"Function\": \"Software development\",\n",
        "          \"Prices\": [\n",
        "          {\n",
        "          \"Cost per unit\": 300,\n",
        "          \"Tier Category\": \"Basic\"\n",
        "          },\n",
        "          {\n",
        "          \"Cost per unit\": 900,\n",
        "          \"Tier Category\": \"Advanced\"\n",
        "          }\n",
        "          ],\n",
        "          \"Currency\": \"GBP\",\n",
        "          \"Quantity/Unit\": \"per FTE\"\n",
        "          },\n",
        "          {\n",
        "          \"Service\": \"Laptops\",\n",
        "          \"Function\": \"Hardware for use on project\",\n",
        "          \"Prices\": [\n",
        "          {\n",
        "          \"Cost per unit\": 4500,\n",
        "          \"Tier Category\": \"Project 1\"\n",
        "          \"Tier Subcategory\": \"Simple\"\n",
        "          },\n",
        "          {\n",
        "          \"Cost per unit\": 6700,\n",
        "          \"Tier Category\": \"Project 1\"\n",
        "          \"Tier Subcategory\": \"Complex\"\n",
        "          }\n",
        "\n",
        "          ],\n",
        "          \"Currency\": \"USD\",\n",
        "          \"Quantity/Unit\": \"1\"\n",
        "          },\n",
        "\n",
        "          ]\n",
        "          }\n",
        "          }\n",
        "\n",
        "          PDF Input:\n",
        "        \"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def extract_pdf_content_stream(pdf_path,prompt, temperature=0.1):\n",
        "        pdf_file = Part.from_uri(pdf_path,mime_type=\"application/pdf\")\n",
        "        generation_config = {\n",
        "          \"max_output_tokens\": 8192,\n",
        "          \"temperature\": temperature,\n",
        "          \"top_p\": 0.95,\n",
        "        }\n",
        "        content = [pdf_file, prompt]\n",
        "        extraction_model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "        responses= extraction_model.generate_content(content, generation_config=generation_config, stream = True)\n",
        "        output = \"\"\n",
        "        for response in responses:\n",
        "          output = output + response.text\n",
        "          print(response.text, end=\"\") #TODO: Do something with this data (e.g. store in BQ, output as a JSON to GCS)\n",
        "        return output\n",
        "\n",
        "    def parse_json_from_gemini_output(output, filename, rate_card_index):\n",
        "        start_marker = \"```json\"\n",
        "        end_marker = \"```\"\n",
        "        start_index = output.find(start_marker) + len(start_marker)\n",
        "        end_index = output.find(end_marker, start_index)\n",
        "        json_string = output[start_index:end_index].strip()\n",
        "        json_string = json_string.replace('\\\\\"', '\"')  # Replace escaped quotes\n",
        "        json_string = json_string.replace(\"Quantity/Unit\",\"Quantity or Unit\")\n",
        "        extracted_json = json.loads(json_string)\n",
        "        extracted_json[\"Rate Card\"][\"Contract ID\"] = filename\n",
        "        extracted_json[\"Rate Card\"][\"Rate Card Index\"] = rate_card_index\n",
        "        with open('data.json', 'w') as f:\n",
        "            json.dump(extracted_json, f)\n",
        "        #upload_to_bq(extracted_json,\"rate_card\")\n",
        "        return extracted_json\n",
        "\n",
        "    structure = table['format']['structure']\n",
        "    title = table['table_title']\n",
        "    index = table['rate_card_index']\n",
        "    columns, rows = extract_row_col(structure)\n",
        "    page_refs = table['table_exists_on_pages']\n",
        "    num_pages = count_page_references(page_refs)\n",
        "    print(f\"Columns: {columns}, Rows: {rows} , Number of pages: {num_pages} , title = {title}.pdf\" )\n",
        "    try:\n",
        "        file_path = str(index)+\".pdf\"\n",
        "    except:\n",
        "        file_path = \"None.pdf\"\n",
        "    print(file_path)\n",
        "    #if (columns < 3 and rows < 10 and num_pages == 1): -- send to DocAI\n",
        "    if 1==1:\n",
        "        print(\"Send to Gemini\")\n",
        "        print(\"Extracting rate card table \" + str(index))\n",
        "        prompt = get_extraction_prompt(table_info)\n",
        "        file_path = \"gs://processing-rate-cards/\"+file_path\n",
        "        while retry_count < max_retries and output is None:\n",
        "            try:\n",
        "                if (retry_count >= 3):\n",
        "                    temperature = 0.5\n",
        "                else:\n",
        "                    temperature = 0.1\n",
        "                output = extract_pdf_content_stream(pdf_path, prompt, temperature)\n",
        "                parsed_json_output = parse_json_from_gemini_output(output,gcs_blob_name,index)\n",
        "                print(\"Extraction complete\")\n",
        "            except Exception as e:\n",
        "              print(f\"Error during parsing: {e}\")\n",
        "              retry_count += 1\n",
        "              time.sleep(5)\n",
        "        if parsed_json_output is None:\n",
        "            raise RuntimeError(\"Failed to extract data after retries\")\n",
        "\n",
        "    # return json.dumps(parsed_json_output, sort_keys=True)\n",
        "    print(\"Processed Table:\")\n",
        "    print(parsed_json_output)\n",
        "    return parsed_json_output\n",
        "\n",
        "extracted_data = process_table(table, document='rate01.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYDrT8wCjnzk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715159761131,
          "user_tz": -60,
          "elapsed": 39595,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "54bb6954-740d-4d4c-fc6a-331b1e85d65d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: 2, Rows: 19 , Number of pages: 1 , title = Worldwide Production Hourly Rates (USD).pdf\n",
            "1.pdf\n",
            "Send to Gemini\n",
            "Extracting rate card table 1\n",
            "```json\n",
            "{\n",
            "  \"Rate Card\": {\n",
            "    \"Rate Card Category\": \"Worldwide Production Hourly Rates\",\n",
            "    \"Line Item\": [\n",
            "      {\n",
            "        \"Service\": \"Creative Development\",\n",
            "        \"Function\": \"Creative Director\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 63\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Creative Development\",\n",
            "        \"Function\": \"Head of Art/ Senior Art Director\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 50\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Creative Development\",\n",
            "        \"Function\": \"Head of copy / Senior Copywriter\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 39\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Creative Development\",\n",
            "        \"Function\": \"Art Director / Copywriter\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 28\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Creative Development\",\n",
            "        \"Function\": \"Designer\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 14\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Creative Development\",\n",
            "        \"Function\": \"Flash Designer / Animator\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 30\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Project Management\",\n",
            "        \"Function\": \"Senior Project Manager\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 40\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Project Management\",\n",
            "        \"Function\": \"Project Manager\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 29\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Project Management\",\n",
            "        \"Function\": \"Junior Product manager\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 14\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Technology & Digital Studio\",\n",
            "        \"Function\": \"Production Manager\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 36\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Technology & Digital Studio\",\n",
            "        \"Function\": \"Technology Director\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 63\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Technology & Digital Studio\",\n",
            "        \"Function\": \"Senior Systems Administrator / Senior Information Archite\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 41\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Technology & Digital Studio\",\n",
            "        \"Function\": \"Systems Administrator / Software Developer\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 32\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Technology & Digital Studio\",\n",
            "        \"Function\": \"Information Architect\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 27\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Technology & Digital Studio\",\n",
            "        \"Function\": \"QA\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 17\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Data Management\",\n",
            "        \"Function\": \"Senior Database Architect\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 41\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Data Management\",\n",
            "        \"Function\": \"Database Architect / SQL Programming\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 33\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Data Management\",\n",
            "        \"Function\": \"Senior Analyst\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 40\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Data Management\",\n",
            "        \"Function\": \"Data Analyst\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 26\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Programming\",\n",
            "        \"Function\": \"Flash Programming\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 34\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Programming\",\n",
            "        \"Function\": \"DHTML/HTML & CSS Programming\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 17\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Programming\",\n",
            "        \"Function\": \"JavaScript/VBScript programming / JAVA Developer\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 30\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Programming\",\n",
            "        \"Function\": \"Perl Programming\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 41\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Programming\",\n",
            "        \"Function\": \"Cold Fusion/ASP/PHP Developer\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 36\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      },\n",
            "      {\n",
            "        \"Service\": \"Programming\",\n",
            "        \"Function\": \"XML/WAP Programming\",\n",
            "        \"Prices\": [\n",
            "          {\n",
            "            \"Cost per unit\": 30\n",
            "          }\n",
            "        ],\n",
            "        \"Currency\": \"USD\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "```Extraction complete\n",
            "Processed Table:\n",
            "{'Rate Card': {'Rate Card Category': 'Worldwide Production Hourly Rates', 'Line Item': [{'Service': 'Creative Development', 'Function': 'Creative Director', 'Prices': [{'Cost per unit': 63}], 'Currency': 'USD'}, {'Service': 'Creative Development', 'Function': 'Head of Art/ Senior Art Director', 'Prices': [{'Cost per unit': 50}], 'Currency': 'USD'}, {'Service': 'Creative Development', 'Function': 'Head of copy / Senior Copywriter', 'Prices': [{'Cost per unit': 39}], 'Currency': 'USD'}, {'Service': 'Creative Development', 'Function': 'Art Director / Copywriter', 'Prices': [{'Cost per unit': 28}], 'Currency': 'USD'}, {'Service': 'Creative Development', 'Function': 'Designer', 'Prices': [{'Cost per unit': 14}], 'Currency': 'USD'}, {'Service': 'Creative Development', 'Function': 'Flash Designer / Animator', 'Prices': [{'Cost per unit': 30}], 'Currency': 'USD'}, {'Service': 'Project Management', 'Function': 'Senior Project Manager', 'Prices': [{'Cost per unit': 40}], 'Currency': 'USD'}, {'Service': 'Project Management', 'Function': 'Project Manager', 'Prices': [{'Cost per unit': 29}], 'Currency': 'USD'}, {'Service': 'Project Management', 'Function': 'Junior Product manager', 'Prices': [{'Cost per unit': 14}], 'Currency': 'USD'}, {'Service': 'Technology & Digital Studio', 'Function': 'Production Manager', 'Prices': [{'Cost per unit': 36}], 'Currency': 'USD'}, {'Service': 'Technology & Digital Studio', 'Function': 'Technology Director', 'Prices': [{'Cost per unit': 63}], 'Currency': 'USD'}, {'Service': 'Technology & Digital Studio', 'Function': 'Senior Systems Administrator / Senior Information Archite', 'Prices': [{'Cost per unit': 41}], 'Currency': 'USD'}, {'Service': 'Technology & Digital Studio', 'Function': 'Systems Administrator / Software Developer', 'Prices': [{'Cost per unit': 32}], 'Currency': 'USD'}, {'Service': 'Technology & Digital Studio', 'Function': 'Information Architect', 'Prices': [{'Cost per unit': 27}], 'Currency': 'USD'}, {'Service': 'Technology & Digital Studio', 'Function': 'QA', 'Prices': [{'Cost per unit': 17}], 'Currency': 'USD'}, {'Service': 'Data Management', 'Function': 'Senior Database Architect', 'Prices': [{'Cost per unit': 41}], 'Currency': 'USD'}, {'Service': 'Data Management', 'Function': 'Database Architect / SQL Programming', 'Prices': [{'Cost per unit': 33}], 'Currency': 'USD'}, {'Service': 'Data Management', 'Function': 'Senior Analyst', 'Prices': [{'Cost per unit': 40}], 'Currency': 'USD'}, {'Service': 'Data Management', 'Function': 'Data Analyst', 'Prices': [{'Cost per unit': 26}], 'Currency': 'USD'}, {'Service': 'Programming', 'Function': 'Flash Programming', 'Prices': [{'Cost per unit': 34}], 'Currency': 'USD'}, {'Service': 'Programming', 'Function': 'DHTML/HTML & CSS Programming', 'Prices': [{'Cost per unit': 17}], 'Currency': 'USD'}, {'Service': 'Programming', 'Function': 'JavaScript/VBScript programming / JAVA Developer', 'Prices': [{'Cost per unit': 30}], 'Currency': 'USD'}, {'Service': 'Programming', 'Function': 'Perl Programming', 'Prices': [{'Cost per unit': 41}], 'Currency': 'USD'}, {'Service': 'Programming', 'Function': 'Cold Fusion/ASP/PHP Developer', 'Prices': [{'Cost per unit': 36}], 'Currency': 'USD'}, {'Service': 'Programming', 'Function': 'XML/WAP Programming', 'Prices': [{'Cost per unit': 30}], 'Currency': 'USD'}], 'Contract ID': 'rate01.pdf', 'Rate Card Index': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Script to save ground truth to BQ\n",
        "\n",
        "def upload_to_bq(data_dict, destination_table):\n",
        "    client = bigquery.Client()\n",
        "    errors = client.insert_rows_json(\n",
        "        f\"{PROJECT_ID}.{DATASET_ID}.{destination_table}\", [data_dict]\n",
        "    )\n",
        "    if errors == []:\n",
        "        print(\"New row successfully added to \" + f\"{PROJECT_ID}.{DATASET_ID}.{destination_table}\")\n",
        "    else:\n",
        "        print(\"Encountered errors while inserting row: \", errors)\n",
        "\n",
        "upload_to_bq(extracted_data,destination_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6ipZ95BA84Y",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715037474719,
          "user_tz": -60,
          "elapsed": 506,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ee941f7a-f59c-4cee-a57b-9dda14a0bb4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New row successfully added to gen-ai-sandbox.ratecard_extraction.extracted_ratecards\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_table_ground_truth(table: dict, document: str) -> dict:\n",
        "    \"\"\"\n",
        "    Reads ground truth data from BigQuery based on the provided table ID.\n",
        "    \"\"\"\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    gcs_blob_name = document\n",
        "\n",
        "    client = bigquery.Client() #project=\"ul-gs-s-sandbx-02-prj\", dataset=\"go_reply_extracted_contract_data\")\n",
        "    # Construct the query based on the contract ID\n",
        "    query = f\"\"\"SELECT *\n",
        "        FROM `gen-ai-sandbox.ratecard_extraction.extracted_ratecards`\n",
        "        WHERE `Rate Card`.`Contract ID` = '{gcs_blob_name}' ;\n",
        "        \"\"\"\n",
        "\n",
        "    # Set the contract ID as a query parameter\n",
        "    query_job = client.query(query)\n",
        "    # Get the results as a dictionary\n",
        "    results = query_job.result()\n",
        "    query_job = client.query(query)\n",
        "    records = [dict(row) for row in query_job]\n",
        "    print(\"records\")\n",
        "    print(records)\n",
        "\n",
        "    #print(first_row[\"Rate Card\"]['Line Item'])\n",
        "\n",
        "    def convert_ndarrays_to_dicts(data):\n",
        "        if isinstance(data, np.ndarray):\n",
        "            # Handle ndarrays (specifically the \"Prices\" key)\n",
        "            if data.dtype == object:  # Check for object dtype (nested ndarrays)\n",
        "                for item in data:\n",
        "                    print(\"Here\")\n",
        "                return [dict(item) for item in data]  # Convert each row to a dictionary\n",
        "            else:\n",
        "                print(\"Here\")\n",
        "                return data.tolist()  # Convert other ndarrays to lists\n",
        "        elif isinstance(data, dict):\n",
        "            print(\"Here\")\n",
        "            return {key: convert_ndarrays_to_dicts(value) for key, value in data.items()}\n",
        "        else:\n",
        "            print(\"Here\")\n",
        "            return data\n",
        "\n",
        "    #ground_truth = convert_ndarrays_to_dicts(first_row)\n",
        "    #print(ground_truth) #[\"Rate Card\"]['Line Item'])\n",
        "\n",
        "    #return ground_truth\n",
        "\n",
        "get_table_ground_truth({},'rate01.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL--A7doM_pv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715163063351,
          "user_tz": -60,
          "elapsed": 1708,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "138239c1-2796-44de-9995-65046aad4577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "records\n",
            "[{'Rate Card': {'Line Item': [{'Prices': [{'Tier Subcategory': None, 'Cost per unit': 63.0, 'Tier Category': None}], 'Service': 'Creative Development', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Creative Director', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 50.0, 'Tier Category': None}], 'Service': 'Creative Development', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Head of Art/ Senior Art Director', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 39.0, 'Tier Category': None}], 'Service': 'Creative Development', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Head of copy / Senior Copywriter', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 28.0, 'Tier Category': None}], 'Service': 'Creative Development', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Art Director / Copywriter', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 14.0, 'Tier Category': None}], 'Service': 'Creative Development', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Designer', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 30.0, 'Tier Category': None}], 'Service': 'Creative Development', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Flash Designer / Animator', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 40.0, 'Tier Category': None}], 'Service': 'Project Management', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Senior Project Manager', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 29.0, 'Tier Category': None}], 'Service': 'Project Management', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Project Manager', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 14.0, 'Tier Category': None}], 'Service': 'Project Management', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Junior Product manager', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 36.0, 'Tier Category': None}], 'Service': 'Technology & Digital Studio', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Production Manager', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 63.0, 'Tier Category': None}], 'Service': 'Technology & Digital Studio', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Technology Director', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 41.0, 'Tier Category': None}], 'Service': 'Technology & Digital Studio', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Senior Systems Administrator / Senior Information Archite', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 32.0, 'Tier Category': None}], 'Service': 'Technology & Digital Studio', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Systems Administrator / Software Developer', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 27.0, 'Tier Category': None}], 'Service': 'Technology & Digital Studio', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Information Architect', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 17.0, 'Tier Category': None}], 'Service': 'Technology & Digital Studio', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'QA', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 41.0, 'Tier Category': None}], 'Service': 'Data Management', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Senior Database Architect', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 33.0, 'Tier Category': None}], 'Service': 'Data Management', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Database Architect / SQL Programming', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 40.0, 'Tier Category': None}], 'Service': 'Data Management', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Senior Analyst', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 26.0, 'Tier Category': None}], 'Service': 'Data Management', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Data Analyst', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 34.0, 'Tier Category': None}], 'Service': 'Programming', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Flash Programming', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 17.0, 'Tier Category': None}], 'Service': 'Programming', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'DHTML/HTML & CSS Programming', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 30.0, 'Tier Category': None}], 'Service': 'Programming', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'JavaScript/VBScript programming / JAVA Developer', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 41.0, 'Tier Category': None}], 'Service': 'Programming', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Perl Programming', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 36.0, 'Tier Category': None}], 'Service': 'Programming', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'Cold Fusion/ASP/PHP Developer', 'Line Total Cost': None}, {'Prices': [{'Tier Subcategory': None, 'Cost per unit': 30.0, 'Tier Category': None}], 'Service': 'Programming', 'Currency': 'USD', 'Location': None, 'Quantity or Unit': None, 'Function': 'XML/WAP Programming', 'Line Total Cost': None}], 'Rate Card Category': 'Worldwide Production Hourly Rates', 'Contract ID': 'rate01.pdf', 'Rate Card Index': '1', 'Rate Card Total Price': None}}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "rate_card_extraction+MLOps_kfp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}